\date{Revised 4 November 2010\\
 ROUGH DRAFT! \\ Please report
errors to: {\tt stark [AT] stat [DOT] berkeley [DOT] edu}}
\input{courseDefs}

\begin{center}

\end{center}
\section{Part 1: Mathematical preliminaries.}

References:
\begin{itemize}
        \item Clark, A., 1984. {\em Elements of Abstract Algebra\/}, Dover.
        \item Hardy, G., J.E. Littlewood, and G. P\'{o}lya, 1952.
                {\em Inequalities, 2nd ed.\/}, Cambridge University Press, Cambridge.
        \item Le Cam, L., 1986. {\em Asymptotic Methods in Statistical Decision Theory\/},
                Springer-Verlag, NY.
        \item Luenberger, D.G., 1997. {\em Optimization by Vector Space Methods\/}, Wiley.
        \item Lugosi, G., 2006. {\em Concentration-of-Measure Inequalities\/}.
        \item Rudin, W., 1991. {\em Functional Analysis\/}, McGraw-Hill.
        \item Stark, P.B., 2010. {\em SticiGui\/}, {\tt statistics.berkeley.edu/users/stark/SticiGui}.
\end{itemize}

\subsection{Sets}
A set is a collection of objects, called members or elements of the set, without
regard for their order.
$a \in A$, pronounced ``$a$ is an element of $A$,''  ``$a$ is in $A$,'' or ``$a$ is a member of
$A$'' means that $a$ is an element of the set $A$.
This is the same as writing $A \ni a$, which is pronounced ``$A$ contains $a$.''
If $a$ is not an element of $A$, we write $a \not \in A$.
Sets may be described explicitly by listing their contents, or implicitly
by specifying a property that all elements of the set share, or a condition
that they satisfy.
The contents of sets are enclosed in curly braces: $\{ \}$.
Examples:

\begin{itemize}
        \item $A = \{a, b, c, d \}$: the set containing the four elements $a$, $b$, $c$, and $d$.
        \item $\emptyset = \{ \}$: the empty set, the set that contains no elements.
        \item $\bfZ \equiv \{ \ldots, -2, -1, 0, 1, 2, \ldots \}$: the integers.
        \item $\bfN \equiv \{1, 2, 3, \ldots \}$: the natural (counting) numbers.
        \item $\bfR \equiv (-\infty, \infty)$: the real numbers.
        \item $\bfR^+ \equiv [-\infty, \infty]$: the extended real numbers.
        \item $\bfC \equiv \{ a + bi: a, b \in \bfR \}$, where $i = \sqrt{-1}$: the complex numbers.
        \item $\bfQ \equiv \{ a/b: a, b \in \bfZ\}$: the rational numbers.
\end{itemize}

$B$ is a {\em subset\/} of $A$, written $B \subset A$ or $A \supset B$, if every element
of the set $B$ is also an element of the set $A$.
Thus $\bfN \subset \bfZ \subset \bfQ \subset \bfR \subset \bfC$.
The empty set $\emptyset$ is a subset of every set.
If $A \subset B$ and $B \subset A$, $A$ and $B$ are the same set, and we write $A = B$.
If $B$ is not a subset of $A$, we write $B \not \subset A$ or $A \not \supset B$.
$B$ is a {\em proper subset\/} of $A$ if $B \subset A$ but
$A \not \subset B$.

The {\em complement\/} of $A$ (with respect to the universe $\calX$), written $A^c$ or $A'$,
is the set of all objects under consideration ($\calX$) that are not elements of $A$.
That is, $A^c \equiv \{ a \in \calX : a \not \in A\}$.

The {\em intersection} of $A$ and $B$, written $A \cap B$ or $AB$, is the set of all objects that
are elements of both $A$ and $B$:
\beq
        A \cap B \equiv \{a: a \in A \mbox{ and } a \in B \}.
\eeq
If $A \cap B = \emptyset$, we say $A$ and $B$ are {\em disjoint\/} or {\em mutually
exclusive\/}.

The {\em union} of $A$ and $B$, written $A \cup B$, is the set of all objects that
are elements of $A$ or of $B$ (or both):
\beq
        A \cup B \equiv \{a: a \in A \mbox{ or } a \in B \mbox{ or both} \}.
\eeq

The {\em difference} of $A$ and $B$, $A \setminus B$, pronounced ``$A$ minus $B$,'' is
the set of all elements of $A$ that are not elements of $B$:
\beq
        A \setminus B \equiv \{a \in A : a \not \in B \} = A \cap B^c.
\eeq

{\em Intervals\/} are special subsets of $\bfR$:
\begin{eqnarray*}
        [a, b] &\equiv& \{x \in \bfR : a \le x \le b\}\cr
        (a, b] &\equiv& \{x \in \bfR : a < x \le b\}\cr
        [a, b) &\equiv& \{x \in \bfR : a \le x < b\}\cr
        (a, b) &\equiv& \{x \in \bfR : a < x < b\}.
\end{eqnarray*}

Sometimes we have a collection of sets, indexed by elements of another
set: $\{A_\beta : \beta \in B \}$.
Then $B$ is called an {\em index set\/}.
If $B$ is a subset of the integers $\bfZ$, usually we write $A_i$ or $A_j$, etc.,
rather than $A_\beta$.
If $B = \bfN$, we usually write $\{A_j\}_{j=1}^\infty$ rather than
$\{A_\beta : \beta \in \bfN \}$.
\beq
        \bigcap_{\beta \in B} A_\beta \equiv \{a: a \in A_\beta \;\;\forall \beta \in B \}.
\eeq
($\forall$ means ``for all.'')
If $B = \{1, 2, \ldots, n\}$, we usually write $\bigcap_{j=1}^n A_j$ rather than
$\bigcap_{j \in \{1, 2, \ldots, n\}} A_j$.
The notation $\bigcup_{\beta \in B} A_\beta$ and $\bigcup_{j=1}^n A_j$ are defined analogously.

A collection of sets $\{A_\beta : \beta \in B \}$ is {\em pairwise disjoint\/}
if $A_\beta \cap A_{\beta'} = \emptyset$ whenever $\beta \ne \beta'$.
The collection $\{A_\beta : \beta \in B\}$ {\em exhausts\/} or {\em covers\/}
the set $A$ if $A \subset \bigcup_{\beta \in B} A_\beta$.
The collection $\{A_\beta : \beta \in B \}$ is a {\em partition\/} of the
set $A$ if $A = \cup_{\beta \in B} A_\beta$ and the sets $\{A_\beta : \beta \in B \}$
are pairwise disjoint.
If $\{A_\beta : \beta \in B \}$ are pairwise disjoint and exhaust $A$, then
$\{A_\beta \cap A : \beta \in B \}$ is a partition of $A$.

A set is {\em countable} if its elements can be put in one-to-one correspondence with
a subset of $\bfN$.
A set is {\em finite} if its elements can be put in one-to-one correspondence with
$\{1, 2, \ldots, n\}$ for some $n \in \bfN$.
If a set is not finite, it is infinite.
$\bfN$, $\bfZ$, and $\bfQ$ are infinite but countable; $\bfR$ is infinite and uncountable.

The notation $\card A$, pronounced ``the cardinality of $A$'' is the size of the set $A$.
If $A$ is finite, $\card A$ is the number of elements in $A$.
If $A$ is not finite but $A$ is countable (if its elements can be put in one-to-one
correspondence with the elements of $\bfN$), then $\card A = \aleph_0$ (aleph-null).

The {\em power set} of a set $A$ is the set of all subsets of the set $A$.
For example, the power set of $\{a, b, c\}$ is
\beq
        \{ \emptyset, \{a\}, \{b\}, \{c\}, \{a, b\}, \{a, c\}, \{b, c\}, \{a, b, c\} \}.
\eeq
If $A$ is a finite set, the cardinality of the power set of $A$ is $2^{\card A}$.
This can be seen as follows: suppose $\card A = n$ is finite.
Consider the elements of $A$ to be written in some canonical order.
We can specify an element of the power set by an $n$-digit binary number.
The first digit is 1 if the first element of $A$ is in the subset, and 0 otherwise.
The second digit is 1 if the second element of $A$ is in the subset, and 0 otherwise,
etc.
There are $2^n$ $n$-digit binary numbers, so there are $2^n$ subsets.
The cardinality of the power set of $\bfN$ is not $\aleph_0$.

If $A$ is a finite set, $B$ is a countable set
and $\{A_j : \beta \in B \}$ is a partition of $A$, then
\beq
        \card A = \sum_{\beta \in B} \card A_\beta.
\eeq

\subsection{Cartesian Products}
The notation $(s_1, s_2, \ldots, s_n) \equiv (s_j)_{j=1}^n$ denotes an 
{\em ordered $n$-tuple\/} consisting of 
$s_1$ in the first position, $s_2$ in the second position, etc.
The parentheses are used instead of curly braces to distinguish 
$n$-tuples from sets: $(s_j)_{j=1}^n \ne \{s_j\}_{j=1}^n$.
The $k$th
{\em component\/} of the $n$-tuple $s = (s_j)_{j=1}^n$, is $s_k$, 
$k = 1, 2, \ldots, n$.
Two $n$-tuples are equal if their components are equal.
That is, $(s_j)_{j=1}^n = (t_j)_{j=1}^n$ means that
$s_j = t_j$ for $j = 1, \ldots, n$.
In particular, $(s, t) \ne (t, s)$ unless $s=t$.
In contrast, $\{s, t \} = \{ t, s \}$ always.

The {\em Cartesian product of $S$ and $T$\/} is
$S \bigotimes T \equiv \{(s, t): s \in S \mbox{ and } t \in T\}$.
Unless $S = T$, $S \bigotimes T \ne T \bigotimes S$.
$\bfRn$ is the Cartesian product of $\bfR$ with itself, $n$ times; its elements
are $n$-tuples of real numbers.
If $s$ is the $n$-tuple $(s_1, s_2, \ldots, s_n) = (s_j)_{j=1}^n$, 

Let $A$ be a finite set with $\card A = n$.
A {\em permutation\/} of (the elements of) $A$ is an element $s$ of 
$\bigotimes_{j=1}^n A = A^n$
whose components are distinct elements of $A$.
That is, $s = (s_j)_{j=1}^n \in A^n$ is a permutation of $A$ if
$\card \{s_j\}_{j=1}^n = n$.
There are $n! = n(n-1)\cdots 1$ permutations of a set with $n$ elements:
there are $n$ choices for the first component of the permutation, $n-1$ choices for
the second (whatever the
first might be), $n-2$ for the third (whatever the first two might be), etc.
This is an illustration of the {\em fundamental rule of counting\/}:
in a sequence of $n$ choices, if there are $m_1$ possibilites for the first choice,
$m_2$ possibilities for the second choice (no matter which was chosen in the first place),
$m_3$ possibilities for the third choice 
(no matter which were chosen in the first two places),
and so on, then there are $m_1 m_2 \cdots m_n = \prod_{j=1}^n m_j$ possible sequences
of choices in all.

The number of permutations of $n$ things taken $k$ at a time, ${}_nP_k$,
is the number of ways there are of selecting $k$ of $n$ things, then permuting
those $k$ things.
There are $n$ choices for the object that will be in the first place in the permutation,
$n-1$ for the second place (regardless of which is first), etc., and $n-k+1$ choices
for the item that will be in the $k$th place.
By the fundamental rule of counting, it follows that
${}_nP_k = n(n-1)\cdots(n-k+1) = n!/(n-k)!$.

The number of subsets of size $k$ that can be formed from $n$ objects is
\beq
        {}_nC_k = {{n}\choose{k}} = 
        {}_nP_k/k! = n(n-1)\cdots(n-k+1)/k! = \frac{n!}{k!(n-k)!}.
\eeq
Because the power set of a set with $n$ elements can be partitioned as
\beq
        \cup_{k=0}^n \left \{ \mbox{all subsets of size $k$}
        \right \},
\eeq
it follows that
\beq
        \sum_{j=0}^n {}_nC_k = 2^n.
\eeq

\subsection{Mappings and Functions}
Functions are subsets of Cartesian products.
We write $f: \calX \rightarrow \calY$, pronounced ``$f$ maps $\calX$ into $\calY$''
or ``$f$ is a function with domain $\calX$ and co-domain $\calY$'' if
$f \subset \calX \bigotimes \calY$ such that for each $x \in \calX$, $\exists 1 y \in \calY$
such that $(x, y) \in f$.
(The notation $\exists 1 y$ means that there exists exactly one value of $y$.)
The set $\calX$ is called the {\em domain\/} of $f$ and $\calY$ is called the co-domain of $f$.
If the $\calX$-component of an element of $f$ is $x$, we denote the $\calY$-component of that
element of $f$ by $fx$ or $f(x)$, so that $(x, fx) \in f$; we write $f: x \mapsto y=f(x)$.
The functions $f$ and $g$ are equal if they are the same subset of $\calX \bigotimes \calY$,
which means that they have the same domain $\calX$, and $fx = gx$ $\forall x \in \calX$.

Let $A \subset \calX$.
The {\em image\/} of $A$ under $f$ is
\[
        fA = f(A) \equiv \{ y \in \calY : (x, y) \in f \mbox{ for some } x \in A\}.
\]
More colloquially, we would write this as
\[
        fA = \{ y \in \calY : f(x) = y \mbox{ for some } x \in A \}.
\]
If $f\calX$ is a proper subset of $\calY$, $f$ is {\em into\/}.
If $f\calX = \calY$, $f$ is {\em onto\/}.
For $B \subset \calY$, the {\em inverse image of $B$ under $f$\/} or
{\em pre-image of $B$ under $f$\/} is
\[
        f^{-1}B \equiv \{ x \in \calX : fx \in B \}.
\]
Similarly, $f^{-1}y \equiv \{ x \in \calX : fx = y \}$
If $\forall y \in \calY$, $\card \{ f^{-1} y \} \le 1$, $f$ is {\em one-to-one\/} (1:1).
If $f$ is one-to-one and onto, i.e., if $\forall y \in \calY$, $\card \{ f^{-1}y \} = 1$,
$f$ is a {\em bijection\/}.

\begin{Exercise}
        \begin{enumerate}
                \item Does $f^{-1}(fA) = A$?
                \item Does $f(f^{-1}B) = B$?
                \item Does $f^{-1}(C \cap D) = f^{-1}C \cap f^{-1} D$?
                \item Does $f(C \cap D) = fC \cap fD$?
                \item Does $f(C \cup D) = fC \cup fD$?
        \end{enumerate}
\end{Exercise}

\subsection{Groups}
\begin{Definition}
        A {\em group\/} is an ordered pair $(\calG, \times)$, where $\calG$ is
        a collection of objects (the elements of the group) and $\times$ is a mapping
        from $\calG \bigotimes \calG$ onto $\calG$,
        \begin{eqnarray*}
                \times : & \calG \bigotimes \calG & \rightarrow \calG \\
                         & (a, b) & \mapsto a \times b,
        \end{eqnarray*}
        satisfying the following axioms:
        \begin{enumerate}
                \item $\exists e \in \calG$ s.t. $\forall a \in \calG$, $e \times a = a$.
                        The element $e$ is called the {\em identity\/}.
                \item For each $a \in \calG$, $\exists a^{-1} \in \calG$ s.t. $a^{-1}\times a = e$.
                        (Every element has an inverse.)
                \item If $a, b, c \in \calG$, then $a \times (b \times c) = (a \times b)\times c$.
                        (The group operation is associative.)
        \end{enumerate}
        If, in addition, for every $a, b \in \calG$,  $a \times b = b \times a$ (if the group
        operation commutes), we say that $(\calG, \times)$ is an {\em Abelian group\/}
        or {\em commutative group\/}.
\end{Definition}

Examples of groups include the real numbers together with ordinary addition, $(\bfR, +)$;
the real numbers other than zero together with ordinary multiplication,
$(\bfR \setminus \{0\}, *)$; the rational numbers together with ordinary addition,
$(\bfQ, +)$; and the integers 0 to $p-1$, $p$ prime, together with addition modulo $p$,
$( \{0, 1, \ldots, p-1\}, +)$.

\begin{Exercise}
        \begin{enumerate}
                \item Show that $\forall a \in \calG$, $a \times a^{-1} = e$.
                        (The inverse from the left is also the
                        inverse from the right; equivalently, $(a^{-1})^{-1} = a$.)
                \item Show that $\forall a \in \calG$, $ae = a$. (The identity from the left is
                        also the identity from the right.)
        \end{enumerate}
\end{Exercise}

\subsection{Fields}

\begin{Definition}
        An ordered triple $(\calF, \times, +)$ is a {\em field\/} if $\calF$ is
        a collection of objects and $\times$ and $+$ are operations on $\calF \times \calF$
        such that
        \begin{enumerate}
                \item $\calF$ is an Abelian group under the operation $+$, with identity 0.
                \item $\calF \setminus \{0\}$ is an Abelian group under the operation $\times$,
                        with identity $1$.
                \item $\times$ is distributive over $+$. I.e., for any $a$, $b$, $c \in \calF$
                        $a \times (b+c) = a \times b + a \times c$ and
                        $(a+b) \times c = a\times c + b \times c$.
        \end{enumerate}
        The additive inverse of $a$ is denoted $-a$; the multiplicative inverse of $a$ is
        $a^{-1} = 1/a$.
\end{Definition}

Examples:
$(\bfR, \times, +)$, where $\times$ is ordinary (real) multiplication and $+$ is ordinary
(real) addition.
The complex numbers $\bfC$, with complex multiplication and addition.

These (and the extended reals) are the only fields we will use.

\subsection{Arithmetic with $\infty$}
We shall use the following conventions:
\begin{itemize}
        \item $0 \cdot \infty = \infty \cdot 0 = 0$
        \item $x + \infty = \infty + x = \infty$, $x \in \bfR$
        \item $x \cdot \infty = \infty \cdot x = \infty$, $x > 0$
\end{itemize}
With these conventions, $([-\infty, \infty], \times, +)$ is a field.

\subsection{Linear Vector Spaces}
\begin{Definition}
        A linear vector space is an ordered quadruple
        $\left ( (\calF, \times, +_1), \calX, \cdot, +_2 \right )$
        where $(\calF, \times, +_1)$ is a field, $\calX$ is a set of objects (the vectors),
        and $\cdot$ is an operation on $\calF \bigotimes \calX$ and $+_2$ is
        an operation on $\calX \bigotimes \calX$ such that:
        \begin{enumerate}
                \item $(\calX, +_2)$ is an Abelian group with identity 0 (the zero vector)
                \item $\cdot : \calF \times \calX \rightarrow \calX$; $(\alpha, x) \mapsto \alpha \cdot x$
                        such that:
                        \begin{enumerate}
                                \item If $1$ is the multiplicative identity on $\calF$, $1 \cdot x = x$
                                        $\forall x \in \calX$.
                                \item $\alpha \cdot (x +_2 y) = \alpha \cdot x +_2 \alpha \cdot y$
                                        $\forall \alpha \in \calF$, $x, y \in \calX$. (distribution)
                                \item $\alpha \cdot (\beta \cdot x) = (\alpha \times \beta) \cdot x$
                                        $\forall \alpha, \beta \in \calF, x \in \calX$. (association)
                                \item $(\alpha +_1 \beta) \cdot x = \alpha \cdot x +_2 \beta \cdot x$,
                                        $\forall \alpha, \beta \in \calF$, $x \in \calX$. (distribution)
                        \end{enumerate}
        \end{enumerate}
\end{Definition}
We rarely distinguish notationally between $+_1$ and $+_2$, between $\times$ and $\cdot$,
or between the additive identity $0$ of the field $\calF$ and the identity $0$
of the Abelian group $\calX$.
Sometimes, the multiplication symbols are omitted; e.g., $\alpha \cdot x = \alpha x$.
Usually, one just calls $\calX$ a linear vector space (LVS), omitting mention of the other elements of
the quadruple.
For our purposes, $\calF$ is almost always $\bfR$.
In that case, $\calX$ is called a real linear vector space (RLVS).

\begin{Definition}
        A {\em functional\/} on a linear vector space is a mapping from the vectors $\calX$
        to the field $\calF$ of the linear vector space.
\end{Definition}

\begin{Definition}
        A {\em linear combination\/} of $\{ x_j\}_{j=1}^n \subset \calX$, $\calX$ a linear
        vector space, is a vector $x = \sum_{j=1}^n \alpha_j x_j$, where
        $\{ \alpha_j\}_{j=1}^n \subset \calF$
        A set $\{x_\alpha : \alpha \in A \} \subset \calX$ is {\em linearly dependent\/}
        if there exist constants $\{ \beta_\alpha : \alpha \in A \} \subset \calF$, not all
        equal to zero, such that $\sum_{\alpha \in A} \beta_\alpha x_\alpha = 0$.
        A set is {\em linearly independent\/} if it is not linearly dependent.
\end{Definition}

\begin{Definition}
        A {\em subspace\/} of a linear vector space $\calX$ is a subset of $\calX$ that is
        a linear vector space with the same field $\calF$ and operations $+_1, \cdot, +_2, \times$
        as $\calX$.
\end{Definition}


\begin{Definition}
        Let $\calX$ be a linear vector space, $A, B \subset \calX$, $x \in x$, $\alpha \in \calF$.
        \begin{itemize}
                \item $\alpha A \equiv \{ \alpha a : a \in A\}$
                \item $-A \equiv \{ -1 \cdot a : a \in A \}$
                \item $x + A \equiv \{x+a : a \in A \} = A + x$
                \item $x - A \equiv \{ x - a: a \in A \}$
                \item $A + B \equiv \{ a + b: a \in A, b \in B \}$
        \end{itemize}
\end{Definition}

\begin{Exercise}
        \begin{enumerate}
                \item Does $x - A = -(A - x)$?
                \item Does $A + A = 2A$?
                \item When does $A - A = 2A$?
        \end{enumerate}
        If you cannot find necessary conditions, give sufficient ones.
\end{Exercise}

\begin{Definition}
        A mapping $M$ from a linear vector space $\calX$ into a linear vector space $\calY$
        with the same field $\calF$ is {\em linear\/} iff
        \[
                M(\alpha x + \beta y) = \alpha M x + \beta M y, \;\; \forall \alpha, \beta \in \calF,
                \;\;x, y \in \calX.
        \]
\end{Definition}

\begin{Definition}
        Let $\calX$ be a real linear vector space. A set $C \subset \calX$ is {\em convex\/}
        iff $\alpha C + (1-\alpha)C \subset C$ $\forall \alpha \in [0, 1]$.
        A set $B \subset \calX$ is {\em balanced\/}
        iff $\alpha B \subset B$ $\forall \alpha$ with $|\alpha| \le 1$.
\end{Definition}
Note that this requires us to define $|\cdot |$ on the field $\calF$.
For $\calF = \bfR$, let $|\cdot |$ be absolute value; for $\calF = \bfC$, let $|\cdot|$ be
the modulus.

\begin{Exercise}
        Show that if $C$, $D \subset \calX$ are convex, then
        \begin{enumerate}
                \item $\alpha C$ is convex, $\alpha \in \bfR$
                \item $C \cap D$ is convex.
        \end{enumerate}
\end{Exercise}


\begin{Definition}
        A linear combination $\sum_j \beta_j x_j$ of elements $\{x_j\}$
        of a linear vector space is a {\em convex combination\/} if
        \begin{enumerate}
                \item $\{ \beta_j \} \subset \bfR$,
                \item $\beta_j \ge 0$, $\forall j$, and
                \item $\sum_j \beta_j = 1$.
        \end{enumerate}
\end{Definition}


\begin{Definition}
        The {\em convex hull\/} of a set $A \subset \calX$ is the intersection of
        all convex sets that contain $A$.
        Equivalently, it is the set of all convex combinations of elements of $A$.
        If $C$ is convex, a point $x \in C$ is an {\em extreme point\/} of $C$ if $x$
        cannot be written as a convex combination of a subset of $C$ unless that subset
        contains $x$.
        A {\em polytope\/} is the convex hull of a finite collection of points.
\end{Definition}

\begin{Definition}
        A set $\{ x_\alpha : \alpha \in A \}$ is a {\em basis\/} for a linear vector
        space $\calX$ if every $x \in \calX$ has a {\bf unique\/} representation
        $x = \sum_{\alpha \in A} \beta_\alpha x_\alpha$ with
        $\{ \beta_\alpha: \alpha \in A\} \subset \calF$.
        If $\calX$ has a basis with $n$ elements, $n \in \bfN$, $\calX$ is {\em finite-dimensional\/}
        and the dimension of $\calX$, $\dim(\calX)$, is $n$.
        If $\calX$ is not finite-dimensional, it is {\em infinite-dimensional\/}.
\end{Definition}

\begin{Exercise}
        Show that if $\calY$ is a subspace of $\calX$ and $\dim(\calX)=n$,
        then $\dim(\calY) \le n$.
\end{Exercise}

\begin{Definition}
        A {\em Hamel basis\/} for a linear vector space $\calX$ is a maximal linearly independent
        subset of $\calX$.
\end{Definition}

\subsection{Normed linear vector spaces}
Norms, Cauchy sequences, completeness.

\subsection{Metric spaces}


\subsection{Topological spaces}
Neighborhoods, completeness.  Topologies induced by metrics.
Cauchy sequences.

\subsection{Duals of linear vector spaces}
Linear functionals, duality, norms of linear functionals.

\subsection{Banach Spaces}
Normed linear vector spaces that are complete w.r.t. topology induced by norm.

\subsection{Hilbert Spaces}
Complete inner product spaces.
Self-dual.
Riesz Hilbert space representation theorem.
Isometric isomorphism between $\cH^*$, normed dual of $\cH$, and $\cH$ itself.
That is, every bounded linear functional on $\cH$ can be written as the inner product
with an element of $\cH$; every element of $\cH$ defines a bounded linear functional on
$\cH$; norm of the linear functional and norm of the element are equal.


\subsection{Reproducing Kernel Hilbert Spaces}
Hilbert space $\cH$ of functions on some domain $\cD$.
Point evaluator (the linear functional that evaluates an element of $\cH$ at an
arbitrary point $x \in \cD$)
is a bounded linear functional.
By Riesz representation theorem, point evaluator is the inner product with
an element of $\cH$.
Elements of $\cH$ are functions on $\cD$.  
Denote by $K_x(y)$ the element of $\cH$ corresponding to evaluation at the point $x \in \cD$.
Kernel is $K_x(y)$, viewed as a function of $(x,y) \in \cD \times \cD$. 

Examples: finite-dimensional spaces of functions are reproducing Kernel Hilbert spaces.
Suppose $\cH$ is an $n$-dimensional set of functions.  
Let $\{ f_j(y) \}_{j=1}^n$ be an orthonormal basis for $\cH$, so that any element $f$ of
$\cH$ can be written $f = \sum_{j=1}^n \alpha_j f_j(y)$ for some set of 
real numbers $\{\alpha_j\}_{j=1}^n$.
Since $\{ f_j(y) \}_{j=1}^n$ are orthonormal, $\alpha_j = \langle f, f_j \rangle$.
Hence 
\begin{eqnarray}
    f(x) & = & \sum_{j=1}^n \langle f, f_j \rangle f_j(x) \nonumber \\
          & = &  \langle f, \sum_{j=1}^n f_j(x) f_j \rangle .
\end{eqnarray}
Thus $K_x(y) = \sum_{j=1}^n f_j(x) f_j(y)$.


\subsection{Partial order and convexity}
\begin{Definition}
        A relation $\le$ is a {\em partial order} on a set $\calX$ if for all $x, y, z \in \calX$,
        \begin{enumerate}
                \item $x \le x$, $\forall x \in \calX$
                \item if $x \le y$ and $y \le x$, then $x = y$
                \item if $x \le y$ and $y \le z$ then $x \le z$
        \end{enumerate}
        If, in addition,
                for any $x$, $y \in \calX$, either $x \le y$ or $y \le x$ (or both), then
                $\le$ is an {\em order\/}.
\end{Definition}

The usual $\le$ is an order on $\bfR$.
Set inclusion gives an order among the power set (set of all subsets) of a given set:
$x \le y$ if $x \subset y$.
One can think of orders as subsets of $\calX \bigotimes \calX$ or as mappings from
$\calX \bigotimes \calX \rightarrow \{0, 1\}$.
Henceforth, we take $\bfR$ to be ordered by $\le$.

\begin{Definition}
        A set $C \subset \calX$, $\calX$ a linear vector space, is a {\em cone\/} with
        vertex $0$ iff $\alpha C \subset C \;\;\forall \alpha \ge 0$.
        A set $C \subset \calX$, $\calX$ a linear vector space, is a {\em cone with vertex
        $p$\/} if $C = p + C_0$, where $C_0$ is a cone with vertex $0$.
\end{Definition}

\begin{Definition}
        Let $\calX$ be a LVS and let $P \subset \calX$ be a convex cone with vertex $0$.
        For any $x, y \in \calX$, we write $x \le y$ (w.r.t. $P$) if $y - x \in P$.
        The cone $P$ is called the {\em positive cone\/} in $\calX$.
        $N \equiv -P$ is the {\em negative cone\/}.
        We write $x \ge y$ if $y - x \in N$ (equivalently, if $x - y \in P$).
\end{Definition}

{\bf Examples.} In $\bfR$, $[0, \infty)$ is the usual positive cone.
In $\bfRn$, the positive orthant ($n$-tuples whose components are all non-negative)
is the usual positive cone.
The set of non-negative functions and the set of monotone functions can form
the positive cones in some function spaces.

Note: the relation $\le$ defined above is almost--but not quite--a partial order on
the linear vector space $\calX$: it does not satisfy the second axiom.
If $P$ satisfies $(x \in P \mbox{ and } -x \in P)$ implies $x = 0$, then the relation $\le$
is a partial order.

\begin{Exercise}
        For $x$, $y \in \bfRn$, define 
\beq
        R(x, y) = \left \{
              \begin{array}{ll}
                \mbox{true}, & \max_{j=1}^n (y_j - x_j) \ge 0 \cr
                \mbox{false}, & \mbox{otherwise}.
              \end{array}
             \right .
\eeq
        Does $R(\cdot, \cdot)$ define a partial order on $\bfRn$? Why or why not?
\end{Exercise}

\begin{Definition}
        Let $\calX$ and $\calY$ be linear vector spaces, let $P$ be the positive
        cone on $\calY$, and let $T: \calX \rightarrow \calY$ have domain $D$.
        $T$ is {\em convex} if
        \begin{enumerate}
                \item $D$ is a convex subset of $\calX$
                \item $T(\alpha x_1 + (1-\alpha) x_2) \le \alpha T x_1 + (1-\alpha)Tx_2$,
                        $\forall x_1, x_2 \in D$, and all $\alpha \in [0, 1]$.
        \end{enumerate}
\end{Definition}

Note that convexity depends on the definition of the positive cone $P$ in $\calY$!
Convexity and related (such as pseudoconvexity
and quasiconvexity), play a crucial role in optimization theory.
(A mapping $T$ is {\em quasiconvex\/} if its domain is convex and
$T(\alpha x_1 + (1-\alpha) x_2) \le \max(T x_1, Tx_2)$,
                        $\forall x_1, x_2 \in D$, and all $\alpha \in [0, 1]$.)


\begin{Definition}
        Let $T$ be a subset of a linear vector space $\calX$.
        The {\em cone generated by $T$\/} or {\em star of $T$\/}
        is the set
        \beq 
             C(T) \equiv \{ \alpha t: \alpha \in [0, \infty), t \in T \} \subset \calX.
        \eeq 
\end{Definition}

\subsection{General-purpose Inequalities}
\subsubsection{The Arithmetic-Geometric Mean Inequality}
Let $\{ a_j \}_{j=1}^n$ and $\{q_j\}_{j=1}^n$ be sets of nonnegative numbers with
$\sum_j q_j = 1$.
Then
\beq
     \prod_{j=1}^n a_j^{q_j} < \sum_{j=1}^n q_j a_j.
\eeq

\subsubsection{Rearrangement Inequalities}
Two functions, three functions.

\subsubsection{The Triangle Inequality and Generalizations}

\subsection{Cauchy's Inequality}

\subsubsection{The Cauchy-Schwartz Inequality}
If $\cH$ is a Hilbert space and $x , y \in \cH$, then
\beq
    |\langle x, y \rangle | \le \|x\| \| y \|.
\eeq
 

\subsubsection{Parseval's Theorem}

\subsubsection{The Projection Theorem}

\subsection{Probability Inequalities}
This follows~\cite{lugosi06} rather closely.

\subsubsection{A Helpful Identity}
If $X$ is a nonnegative real-valued random variable,
\beq \label{eq:integralExpect}
      \EE X = \int_0^\infty \Pr \{X \ge x\} dx
\eeq

\subsubsection{Jensen's Inequality}
If $\phi$ is a convex function from $\cX$ to $\Re$, then $\phi(\EE X) \le \EE \phi(X)$.



\subsubsection{Markov's, Chebychev's, and related inequalities}
From \ref{eq:integralExpect},
\beq
    \EE X \ge \int_0^t \Pr \{X \ge x\} dx \ge t \Pr \{X \ge t \}
\eeq
so
\beq
  \Pr \{ X \ge t \} \le \frac{\EE X}{t}.
\eeq

Moreover, for any strictly monotonic function $f$ and nonnegative $X$,
\beq \label{eq:monotoneBound}
   \Pr \{ X \ge t \} = \Pr \{ f(X) \ge f(t) \} \le \frac{\EE f(X)}{f(t)}.
\eeq
In particular, for any real-valued $X$ and real $q > 0$,
$| X - \EE X |$ is a nonnegative
random variable and $f(x) = x^q$ is strictly monotonic, so 
\beq
   \Pr \{| X - \EE X | \ge t \} = \Pr \{ | X - \EE X |^q \ge t^q \} \le
             \frac{\EE  | X - \EE X |^q}{t^q}.
\eeq
Chebychev's inequality is a special case:
\beq \label{eq:chebychev}
    \Pr \{ | X - \EE X |^2 \ge t^2 \} \le
             \frac{\EE  | X - \EE X |^2}{t^2}
             = \frac{\Var X}{t^2}.
\eeq

\subsubsection{Chernoff bounds}
Apply \ref{eq:monotoneBound} with $f(x) = e^{sx}$ for positive $s$:
\beq \label{eq:chernoff}
     \Pr \{ X \ge t \} = \Pr \{ e^{sX} \ge e^{st} \} \le \frac{\EE e^{sX}}{e^{st}}
\eeq
for all $s$.
For particular $X$, can optimize over $s$.


\subsubsection{Hoeffding's Inequality}
Let $\{ X_j \}_{j=1}^n$ be independent, and define 
$S_n \equiv \sum_{j=1}^n X_j$.
Then, applying \ref{eq:chernoff} gives
\beq
    \Pr \{ S_n - \EE S_n \ge t \} \le e^{-st} \EE e^{sS_n} =
    e^{-st} \prod_{j=1}^n e^{s(X_j - E X_j)}.
\eeq
Hoeffding bounds the moment generating function for a bounded random variable
$X$:
If $a \le X \le b$ with probability 1, then
\beq
   \EE e^{sX}  \le e^{s^2 (b-a)^2/8},
\eeq
from which follows {\em Hoeffding's tail bound\/}.

If $\{X_j\}_{j=1}^n$ are independent and $\Pr \{a_j \le X_j \le b_j\} = 1$,
then
\beq \label{eq:hoeffdingUpper}
    \Pr \{ S_n - \EE S_n \ge t \} \le e^{-2t^2/\sum_{j=1}^n (b_j - a_j)^2}
\eeq 
and
\beq \label{eq:hoeffdingLower}
    \Pr \{ S_n - \EE S_n \le -t \} \le e^{-2t^2/\sum_{j=1}^n (b_j - a_j)^2}
\eeq 

\subsubsection{Hoeffding's Other Inequality}
Suppose $f$ is a convex, real function and $\cX$ is a finite set.
Let $\{X_j \}_{j=1}^n$ be a simple random sample from $\cX$ and
let $\{Y_j \}_{j=1}^n$ be an iid uniform random sample (with replacement) from $\cX$.
Then
\beq  \label{eq:hoeffding2}
   \EE f \left ( \sum_{j=1}^n X_j \right ) \le \EE f \left ( \sum_{j=1}^n Y_j \right ).
\eeq

\subsubsection{Bernstein's Inequality}
Suppose $\{X_j \}_{j=1}^n$ are independent with $\EE X_j = 0$ for all $j$,
$\Pr \{ | X_j | \le c\} = 1$,
$\sigma_j^2 = \EE X_j^2$ and $\sigma = \frac{1}{n} \sum_{j=1}^n \sigma_j^2$.
Then for any $\epsilon > 0$,
\beq
     \Pr \{ S_n/n > \epsilon \} \le e^{-n \epsilon^2 / 2(\sigma^2 + c\epsilon/3)}.
\eeq

\subsubsection{The Probability Transform}

\subsubsection{The Massart-Dvoretsky-Kiefer-Wolfowitz Inequality}

\subsubsection{Transformed order statistics}

\subsubsection{Martingales; the Optional Stopping Theorem}

\subsubsection{The Neyman-Pearson Lemma}

\subsubsection{Vapnik-Cervonenkis Classes}

\subsubsection{Convergence of Empirical Processes}

\subsection{Optimization}

\subsubsection{Convex optimization}

\subsubsection{Nonsmooth optimization}

\subsubsection{Numerical Programming: Linear, Quadratic, and Integer}

\subsubsection{Combinatorial Problems}

\subsubsection{The Knapsack Problem}



\end{document}


