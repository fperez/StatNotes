
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Hypothesis Testing, Combinations of Tests, and Stratified Tests &#8212; An Idiosyncratic Subset of Statistics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">An Idiosyncratic Subset of Statistics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Notes on Applied Statistics
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Index of Lecture Notes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index-app-stats.html">
   An Idiosyncratic Sample of Applied Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="240-spring-2023/index.html">
   Nonparametric Statistics
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Syllabus Statistics 240, spring 2023
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="240-spring-2023/syllabus.html">
   Syllabus for Statistics 240: Nonparametric and Robust Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="240-spring-2023/assignments.html">
   Assignments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="240-spring-2023/reading.html">
   Reading assignments and collected reading list for nonparametric statistics
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Assignments for Stat 240, spring 2023
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="240-spring-2023/Hw/ps01-background.html">
   1. Problem set 1: Mathematical Preliminaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="240-spring-2023/Hw/ps02-binary-experiments.html">
   2. Problem set: binary experiments with binary outcomes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="240-spring-2023/Hw/cp01-tests.html">
   3. Coding project 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="240-spring-2023/Hw/cp02-function.html">
   4. Coding project 2
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/pbstark/StatNotes/main?urlpath=tree/tests.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/pbstark/StatNotes"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/pbstark/StatNotes/issues/new?title=Issue%20on%20page%20%2Ftests.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/tests.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypotheses">
   Hypotheses
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#types-of-statistical-hypotheses">
     Types of Statistical Hypotheses
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-functions-versus-acceptance-regions">
     Test functions versus acceptance regions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aside-on-notation">
     Aside on notation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#significance-level">
   Significance level
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#power">
   Power
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#type-i-and-type-ii-errors">
   Type I and Type II errors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#type-iii-errors">
   Type III errors
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#randomized-tests">
     Randomized tests
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#p-values">
   <span class="math notranslate nohighlight">
    \(P\)
   </span>
   -values
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-z-test">
   The
   <span class="math notranslate nohighlight">
    \(Z\)
   </span>
   -test
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-of-an-approximate-z-test-with-a-built-in-type-iii-error">
     Example of an approximate
     <span class="math notranslate nohighlight">
      \(Z\)
     </span>
     -test with a built-in Type III error
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numerical-example">
     Numerical example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#an-exact-conditional-test-based-on-invariance-permutation-methods">
     An exact conditional test based on invariance: permutation methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#illustration">
     Illustration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unconditional-tests-from-conditional-tests">
     Unconditional tests from conditional tests
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numerical-comparison">
     Numerical comparison
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithmic-considerations">
     Algorithmic considerations
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#finding-mathcal-i-and-mathcal-j">
       Finding
       <span class="math notranslate nohighlight">
        \(\mathcal{I}\)
       </span>
       and
       <span class="math notranslate nohighlight">
        \(\mathcal{J}\)
       </span>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Algorithmic considerations
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Hypothesis Testing, Combinations of Tests, and Stratified Tests</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypotheses">
   Hypotheses
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#types-of-statistical-hypotheses">
     Types of Statistical Hypotheses
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-functions-versus-acceptance-regions">
     Test functions versus acceptance regions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aside-on-notation">
     Aside on notation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#significance-level">
   Significance level
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#power">
   Power
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#type-i-and-type-ii-errors">
   Type I and Type II errors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#type-iii-errors">
   Type III errors
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#randomized-tests">
     Randomized tests
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#p-values">
   <span class="math notranslate nohighlight">
    \(P\)
   </span>
   -values
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-z-test">
   The
   <span class="math notranslate nohighlight">
    \(Z\)
   </span>
   -test
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-of-an-approximate-z-test-with-a-built-in-type-iii-error">
     Example of an approximate
     <span class="math notranslate nohighlight">
      \(Z\)
     </span>
     -test with a built-in Type III error
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numerical-example">
     Numerical example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#an-exact-conditional-test-based-on-invariance-permutation-methods">
     An exact conditional test based on invariance: permutation methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#illustration">
     Illustration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unconditional-tests-from-conditional-tests">
     Unconditional tests from conditional tests
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numerical-comparison">
     Numerical comparison
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithmic-considerations">
     Algorithmic considerations
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#finding-mathcal-i-and-mathcal-j">
       Finding
       <span class="math notranslate nohighlight">
        \(\mathcal{I}\)
       </span>
       and
       <span class="math notranslate nohighlight">
        \(\mathcal{J}\)
       </span>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Algorithmic considerations
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="hypothesis-testing-combinations-of-tests-and-stratified-tests">
<h1>Hypothesis Testing, Combinations of Tests, and Stratified Tests<a class="headerlink" href="#hypothesis-testing-combinations-of-tests-and-stratified-tests" title="Permalink to this headline">#</a></h1>
<section id="hypotheses">
<h2>Hypotheses<a class="headerlink" href="#hypotheses" title="Permalink to this headline">#</a></h2>
<p>A <em>scientific hypothesis</em> is an assertion about the world, for instance “this drug increases longevity in patients with Alzheimer’s Disease,” “the outcome of the 2020 presidential election would have been different, but for fraud,” “to 6 significant digits, the gravitational constant is <span class="math notranslate nohighlight">\(6.67430e-11 Nm^2kg^{-2}\)</span>,” “the Moderna COVID-19 vaccine is at least 90% effective for at least 6 months for all ages,” “students give female instructorss lower ratings than equally effective male instructors,” “the universe is expanding at an increasing rate,” “there is a black hole at the center of the universe,” or “female faculty job applicants are interrupted more frequently during their job talks than male applicants are.”</p>
<p>A <em>statistical hypothesis</em> is an assertion about the probability distribution <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> of data <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>Generally, statistical hypotheses are interesting only insofar as they help us evaluate scientific
hypotheses.
Whenever a statistical hypothesis is being tested, pay attention to the connection between that hypothesis and the scientific hypothesis it purports to represent.</p>
<section id="types-of-statistical-hypotheses">
<h3>Types of Statistical Hypotheses<a class="headerlink" href="#types-of-statistical-hypotheses" title="Permalink to this headline">#</a></h3>
<p>A <em>simple</em> statistical hypothesis is an assertion that completely specifies the probability distribution of the data, e.g., <span class="math notranslate nohighlight">\(\mathbb{P} = \mathbb{P}_0\)</span> for some distribution <span class="math notranslate nohighlight">\(\mathbb{P}_0\)</span>. Here are some simple hypotheses:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X \sim N(0,1)\)</span> The data have a standard normal distribution.</p></li>
<li><p><span class="math notranslate nohighlight">\(X \sim U[0,1]\)</span> The data have a standard uniform distribution.</p></li>
<li><p><span class="math notranslate nohighlight">\(X \sim N(\mu, \Sigma)\)</span> for a given <span class="math notranslate nohighlight">\(\mu \in \Re^n\)</span> and positive semi-definite <span class="math notranslate nohighlight">\(n \times n\)</span> matrix <span class="math notranslate nohighlight">\(\Sigma\)</span>. The data are jointly normally distributed with mean <span class="math notranslate nohighlight">\(\mu\)</span> and covariance matrix <span class="math notranslate nohighlight">\(\Sigma\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\{X_j\}\; \mbox{IID} \; U[0, 17]\)</span>. The components of the data are independent and identically distributed with a uniform distribution on <span class="math notranslate nohighlight">\([0, 17]\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(X \sim \mbox{Binom}(n, p)\)</span> for given values of <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(p\)</span>. The data have a binomial distribution with parameters <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(p\)</span>.</p></li>
</ul>
<p>A <em>composite</em> hypothesis is an assertion that does not completely specify the distribution; it only says the
distribution is in some specified set of distributions.
E.g., <span class="math notranslate nohighlight">\(\mathbb{P} \in \mathcal{P}_0\)</span> for some set
<span class="math notranslate nohighlight">\(\mathcal{P}_0\)</span> of distributions.
Here are some composite null hypotheses:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X \sim N(\mu,1)\)</span>, <span class="math notranslate nohighlight">\(\mu \in [0, 7]\)</span> The data have a normal distribution with variance 1 and mean between 0 and 7.</p></li>
<li><p><span class="math notranslate nohighlight">\(X \sim \mbox{Binom}(n, p)\)</span>, <span class="math notranslate nohighlight">\(p &gt; 1/2\)</span> (<span class="math notranslate nohighlight">\(n\)</span> given). The data have a binomial distribution with known parameter <span class="math notranslate nohighlight">\(n\)</span> and unknown parameter <span class="math notranslate nohighlight">\(p &gt; 1/2\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}X=0\)</span> The expected value of the data is zero.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}X \le 1/2\)</span> The expected value of the data is at most 1/2.</p></li>
<li><p>The distribution <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> of <span class="math notranslate nohighlight">\(X\)</span> has at most 3 modes.</p></li>
<li><p><span class="math notranslate nohighlight">\(\{X_j\}_{j=1}^n\)</span> are <em>exchangeable</em> (A collection of random variables is <em>exchangeable</em> if their joint distribution is invariant under permuting their labels. If a collection of random variables is IID, it is also exchangeable.)</p></li>
<li><p>The distribution of <span class="math notranslate nohighlight">\(X\)</span> is spherically symmetric</p></li>
<li><p>The <span class="math notranslate nohighlight">\(q\)</span>th quantile of the probability distribution of the data is <span class="math notranslate nohighlight">\(x\)</span></p></li>
</ul>
<p>A common statistical question is to use data to assess whether a statistical hypothesis is true: to <em>test</em> the hypothesis.
There is always more than one explanation for any particular set of data, so in general, it is not
possible to prove that a (simple) statistical hypothesis is <em>true</em>.
But the data might provide evidence that a hypothesis is <em>false</em>.
This is tied to Popper’s notion that only hypotheses that can be falsified by evidence (potentially shown to be false) are scientific hypotheses.</p>
<p>We speak of “rejecting” a hypothesis when there is sufficiently strong evidence that the hypothesis is false.
But if data do not cast doubt on a hypothesis, that is not evidence that the hypothesis is true–it is only absense of evidence that the hypothesis is false.
Additional evidence might cast doubt on the hypothesis.
When we speak (informally) of “accepting” a hypothesis, it means only that we did not reject it on the basis of a particular set of data, not that we
have affirmative evidence that it is true.</p>
<p>To test a statistical hypothesis, one specifies a set <span class="math notranslate nohighlight">\(A\)</span> of possible data values (before examining the data).
If the data fall inside that set, i.e., if <span class="math notranslate nohighlight">\(X \in A\)</span>, the null hypothesis is <em>not rejected</em>; otherwise, the null hypothesis is <em>rejected</em>.
Each (measurable) set <span class="math notranslate nohighlight">\(A\)</span> implicitly defines a hypothesis test.
The set <span class="math notranslate nohighlight">\(A\)</span> is called the <em>acceptance region</em> for the test.</p>
<p>Sometimes the set <span class="math notranslate nohighlight">\(A\)</span> is defined explicitly, but
more often it is defined implicitly in terms of a <em>test statistic</em>, a function of the data that does not depend on any unknown parameters.</p>
<p>For instance an acceptance region for testing the hypothesis that <span class="math notranslate nohighlight">\(\{X_j\}_{j=1}^n\)</span> are IID <span class="math notranslate nohighlight">\(N(0,1)\)</span> might be</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{eqnarray*}
A := \left \{x = \{x_1, \ldots, x_n\}: \frac{1}{n} \sum_{j=1}^n x_j \le \frac{c}{\sqrt{n}} \right \}.
\end{eqnarray*}\]</div>
<p>In this example, the test statistic is the sample mean, and the region <span class="math notranslate nohighlight">\(A\)</span> is the set of all data for which the
sample mean does not exceed <span class="math notranslate nohighlight">\(c/\sqrt{n}\)</span>.</p>
</section>
<section id="test-functions-versus-acceptance-regions">
<h3>Test functions versus acceptance regions<a class="headerlink" href="#test-functions-versus-acceptance-regions" title="Permalink to this headline">#</a></h3>
<p>Instead of working with a set <span class="math notranslate nohighlight">\(A\)</span>, we can work with the indicator function of the set <span class="math notranslate nohighlight">\(A\)</span>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{eqnarray*}
1_A &amp;:&amp; \mathcal{X} \rightarrow \{0, 1\} \\
       &amp;&amp; x  \mapsto \left \{ \begin{array}{ll}
                    1, &amp; x \in A \\
                    0, &amp; \mbox{ otherwise. } 
                    \end{array} \right .
\end{eqnarray*}\]</div>
<p>Then we reject the null hypothesis if <span class="math notranslate nohighlight">\(1_A(X) = 0\)</span> and do not reject it if <span class="math notranslate nohighlight">\(1_A(X) = 1\)</span>.</p>
<p>This can be generalized by using a <em>test function</em> or <em>critical function</em> <span class="math notranslate nohighlight">\(\phi(\cdot)\)</span> that take
values in <span class="math notranslate nohighlight">\([0,1]\)</span> rather than just <span class="math notranslate nohighlight">\(\{0, 1\}\)</span>, as described below.
In that case, when <span class="math notranslate nohighlight">\(X=x\)</span>, the test rejects the null with probability <span class="math notranslate nohighlight">\(1- \phi(x)\)</span>, i.e.,
if <span class="math notranslate nohighlight">\(\phi(X) = 0\)</span>, the test certainly rejects the null;
if <span class="math notranslate nohighlight">\(\phi(X) = 1\)</span>, the test certainly does not reject the null; and if <span class="math notranslate nohighlight">\(\phi(X) = q \in (0, 1)\)</span>,
it rejects the null with probability <span class="math notranslate nohighlight">\(1-q\)</span>.
This is called a <em>randomized test</em>, discussed further below.</p>
</section>
<section id="aside-on-notation">
<h3>Aside on notation<a class="headerlink" href="#aside-on-notation" title="Permalink to this headline">#</a></h3>
<p>The following all mean the same thing, namely, the probability that the random variable <span class="math notranslate nohighlight">\(X\)</span> takes a value in the set <span class="math notranslate nohighlight">\(A\)</span> if the distribution of <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(\mathbb{P}_0\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\Pr \{X \in A || X \sim \mathbb{P}_0 \},
\end{equation*}\]</div>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\Pr_{X \sim \mathbb{P}_0} \{X \in A\},
\end{equation*}\]</div>
<p>and</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P}_0 \{X \in A\}.
\end{equation*}\]</div>
<p>For expectations, we use similar notation:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{E} (X || X \sim \mathbb{P}_0)
\end{equation*}\]</div>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{E}_{X \sim \mathbb{P}_0} X ,
\end{equation*}\]</div>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{E}_{\mathbb{P}_0} X,
\end{equation*}\]</div>
<p>and sometimes</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{E}_0 X
\end{equation*}\]</div>
<p>or even</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P}_0 X
\end{equation*}\]</div>
</section>
</section>
<section id="significance-level">
<h2>Significance level<a class="headerlink" href="#significance-level" title="Permalink to this headline">#</a></h2>
<p>The <em>significance level</em> of the test <span class="math notranslate nohighlight">\(A\)</span> of the simple null hypothesis <span class="math notranslate nohighlight">\(X \sim \mathbb{P}_0\)</span> is the probability that the test rejects the null hypothesis when the null hypothesis is true:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
   \alpha := \mathbb{P}_0 \{X \notin A \}.
\end{equation*}\]</div>
<p>Because the expected value of an indicator function is the probability of the set, this can be written</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
   \alpha := 1-\mathbb{E}_{\mathbb{P}_0} 1_A(X).
\end{equation*}\]</div>
<p>For a test based on the test function <span class="math notranslate nohighlight">\(\phi: \mathcal{X} \rightarrow [0,1]\)</span>,
the significance level of the simple null hypothesis <span class="math notranslate nohighlight">\(X \sim \mathbb{P}_0\)</span> is</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
   \alpha := 1-\mathbb{E}_{\mathbb{P}_0} \phi(X).
\end{equation*}\]</div>
<p>Why is this expression the probability of rejecting the null when the null is true?
The test rejects when <span class="math notranslate nohighlight">\(U \ge \phi(X)\)</span>.
By the law of total expectation (see <a class="reference internal" href="math-inequalities.html"><span class="doc std std-doc">Inequalities and Identities</span></a>) and using the fact that <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(U\)</span> are independent,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P}_{0,U} \{ U \ge \phi(X)\} = 
\mathbb{E}_{\mathbb{P}_0, U} 1_{U \ge \phi(X)} = 
\mathbb{E}_{\mathbb{P}_0} \mathbb{E}_U (1_{U \ge \phi(X)} | \phi(X)) =
\mathbb{E}_{\mathbb{P}_0} (1-\phi(X)) = 1 - \mathbb{E}_{\mathbb{P}_0} \phi(X).
\end{equation*}\]</div>
<p>The <em>significance level</em> of the test <span class="math notranslate nohighlight">\(A\)</span> of the composite null hypothesis <span class="math notranslate nohighlight">\(H_0: X \sim \mathbb{P} \in \mathcal{P}_0\)</span> is</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
   \alpha := \sup_{\mathbb{P} \in \mathcal{P}_0} \mathbb{P} \{X \notin A \}.
\end{equation*}\]</div>
<p>That is, it is the largest probability that that the test rejects the null hypothesis when the null hypothesis is true.
For a test based on a a test function <span class="math notranslate nohighlight">\(\phi: \mathcal{X} \rightarrow [0,1]\)</span>,
the significance level of the simple null hypothesis <span class="math notranslate nohighlight">\(X \sim \mathbb{P}_0\)</span> is</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
   \alpha := 1- \inf_{\mathbb{P_0} \in \mathcal{P}_0} \mathbb{E}_{\mathbb{P}_0} \phi(X).
\end{equation*}\]</div>
<p>When <span class="math notranslate nohighlight">\(\mathcal{P}_0\)</span> contains only one distribution, the two definitions of significance level coincide.</p>
</section>
<section id="power">
<h2>Power<a class="headerlink" href="#power" title="Permalink to this headline">#</a></h2>
<p>The <em>power</em> of the test <span class="math notranslate nohighlight">\(A\)</span> against the simple hypothesis <span class="math notranslate nohighlight">\(H_1: X \sim \mathbb{P}_1\)</span> is</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
   1-\beta := \mathbb{P}_1 \{X \notin A \}
\end{equation*}\]</div>
<p>That is, the power is the chance that the test rejects the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span> when the alternative hypothesis <span class="math notranslate nohighlight">\(H_1\)</span> is true.</p>
<p>For a test based on a test function <span class="math notranslate nohighlight">\(\phi\)</span>, the power is</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
   1-\beta := 1 - \mathbb{E}_{\mathbb{P}_1} \phi(X).
\end{equation*}\]</div>
<p>The <em>power</em> of the test <span class="math notranslate nohighlight">\(A\)</span> against the composite alternative hypothesis <span class="math notranslate nohighlight">\(H_1: X \sim \mathbb{P} \in \mathcal{P}_1\)</span> is</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
   1-\beta := \inf_{\mathbb{P_1} \in \mathcal{P}_1} \mathbb{P}_1 \{X \notin A \}.
\end{equation*}\]</div>
<p>That is, it is the smallest probability that that the test rejects the null hypothesis when the alternative hypothesis is true.</p>
<p>For a test based on a test function <span class="math notranslate nohighlight">\(\phi\)</span>, the power is</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
   1-\beta := 1 - \sup_{\mathbb{P_1} \in \mathcal{P}_1}\mathbb{E}_{\mathbb{P}_1} \phi(X).
\end{equation*}\]</div>
<p>When the alternative <span class="math notranslate nohighlight">\(\mathcal{P}_1\)</span> contains only one distribution, the two definitions coincide.</p>
<p>Power and significance level are the (extremal) probability of the same event–namely, rejecting the null hypothesis–but computed under different assumptions.
The power is computed under the assumption that the alternative hypothesis is true; the significance level is computed under the assumption that the null hypothesis is true.</p>
<p>Seminal work by Jerzy Neyman (the founder of Berkeley’s Department of Statistics) and Egon Pearson showed how to find the most powerful test of a simple null hypothesis against a simple alternative hypothesis among all tests with a given significance level. They showed that the most powerful test had an acceptance region characterized by the likelihood ratio; see below.</p>
</section>
<section id="type-i-and-type-ii-errors">
<h2>Type I and Type II errors<a class="headerlink" href="#type-i-and-type-ii-errors" title="Permalink to this headline">#</a></h2>
<p>A type I error occurs when a test rejects the null hypothesis but the null hypothesis is true.
The chance of a type I error is the significance level of the test.</p>
<p>A type II error occurs when a test does not reject the null hypothesis the null hypothesis is false.
The chance of a type II error when a particular alternative is true is 100% minus the power of the test
against that alternative, i.e., <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
</section>
<section id="type-iii-errors">
<h2>Type III errors<a class="headerlink" href="#type-iii-errors" title="Permalink to this headline">#</a></h2>
<p>There are a number of informal definitions of type III errors.</p>
<p>One is that a Type III error occurs when a test correctly rejects the null hypothesis “for the wrong reason.” For instance, suppose that we test the null hypothesis <span class="math notranslate nohighlight">\(X \sim N(0, 1)\)</span>
at significance level <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span> by defining <span class="math notranslate nohighlight">\(A := \{x: |x| \le 1.96\}\)</span>.
Suppose that in reality <span class="math notranslate nohighlight">\(X \sim N(-1, 1)\)</span> and we observe <span class="math notranslate nohighlight">\(X = 2\)</span>.
Then we would <em>correctly</em> reject <span class="math notranslate nohighlight">\(H_0\)</span>, but because <span class="math notranslate nohighlight">\(X\)</span> was “too big,” while it was much more likely to be “too small” since in reality the distribution of <span class="math notranslate nohighlight">\(X\)</span> has mean <span class="math notranslate nohighlight">\(-1\)</span> instead of <span class="math notranslate nohighlight">\(0\)</span>. (If, after rejecting <span class="math notranslate nohighlight">\(H_0\)</span>, we concluded that <span class="math notranslate nohighlight">\(\mathbb{E}X &gt; 0\)</span>, that directional conclusion would be wrong.)</p>
<p>Similarly, suppose we want to test whether the mean of some finite population is zero from a simple random sample <span class="math notranslate nohighlight">\(X = (X_1, \ldots, X_n)\)</span>.
We set <span class="math notranslate nohighlight">\(A = \{x \in \Re^n : |\bar{x}| \le z_\alpha/\sqrt{n} \}\)</span>, where <span class="math notranslate nohighlight">\(z_\alpha\)</span> is the <span class="math notranslate nohighlight">\(1-\alpha\)</span> percentage
point of the standard normal distribution.
This is a significance level <span class="math notranslate nohighlight">\(\alpha\)</span> test of the null hypothesis that <span class="math notranslate nohighlight">\(X \sim N(0, 1)\)</span> from an IID sample, not
of the null hypothesis that the population mean is zero from a random sample without replacement.
Nonetheless, this incorrect test might correctly reject the null hypothesis.</p>
<p>Another informal definition is that a Type III error occurs when one gets the right answer to the wrong question.
One example is testing the hypothesis <span class="math notranslate nohighlight">\(\mathbb{E}X=0\)</span> by testing the hypothesis <span class="math notranslate nohighlight">\(X \sim N(0, \sigma^2)\)</span> when
there is no reason to think that <span class="math notranslate nohighlight">\(X\)</span> has a normal distribution. Even if the test is performed correctly,
it is testing the wrong null.</p>
<p>In my experience, the most frequent and pernicious Type III errors involve testing a <em>statistical hypothesis</em> that has little or nothing to do with the <em>scientific hypothesis</em> (aside, perhaps, from having some words in common).
<em>Many</em> hypothesis tests in applications have this sort of Type III error baked in.
Indeed, most analyses of clinical trial data I’ve seen test a statistical null hypothesis that involves selecting subjects at random from a superpopulation–which did not occur–rather than test a statistical hypothesis based on the randomization of subjects into treatment or control–which actually did occur.</p>
<p>It is quite common to base <span class="math notranslate nohighlight">\(\mathbb{P}_0\)</span> on a statistical model that has no connection to the scientific hypothesis and how the data were generated, then to claim that rejecting <span class="math notranslate nohighlight">\(\mathbb{P}_0\)</span> says something about the world.
That logic is flawed.</p>
<section id="randomized-tests">
<h3>Randomized tests<a class="headerlink" href="#randomized-tests" title="Permalink to this headline">#</a></h3>
<p>Sometimes it is useful for a hypothesis test to depend not only on the data but also on “auxilliary” randomness, typically a <span class="math notranslate nohighlight">\(U[0, 1]\)</span> variable <span class="math notranslate nohighlight">\(U\)</span> that is independent of the data <span class="math notranslate nohighlight">\(X\)</span>.
Then the acceptance region <span class="math notranslate nohighlight">\(A\)</span> is a subset of the Cartesian product of the data space and <span class="math notranslate nohighlight">\([0, 1]\)</span>.
The null hypothesis is not rejected if <span class="math notranslate nohighlight">\((X, U) \in A\)</span>; otherwise it is rejected.</p>
<p>Randomized tests arise in a number of situations, including tests involving discrete distributions.
Randomized tests are also useful for proving theorems about tests.
For instance, <em>the Neyman-Pearson lemma</em> shows that the most powerful test of a simple null hypothesis <span class="math notranslate nohighlight">\(X \sim \mathbb{P}_0\)</span> against a simple alternative hypothesis <span class="math notranslate nohighlight">\(X \sim \mathbb{P}_1\)</span> at significance level <span class="math notranslate nohighlight">\(\alpha\)</span> is
a randomized test of the form:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
A = \{ (x, u): \mathcal{L}_0(x)/\mathcal{L}_1(x) &gt; c \} \cup \{ (x, u): (\mathcal{L}_0(x)/\mathcal{L}_1(x) = c) \mbox{ and }
  (u \le d) \}
\end{equation*}\]</div>
<p>for suitable choices of <span class="math notranslate nohighlight">\(c\)</span> and <span class="math notranslate nohighlight">\(d\)</span>,
where <span class="math notranslate nohighlight">\(\mathcal{L}_j(x)\)</span> is the likelihood of hypothesis <span class="math notranslate nohighlight">\(j\)</span> for data <span class="math notranslate nohighlight">\(x\)</span>.
(This assumes <span class="math notranslate nohighlight">\(\mathbb{P}_0\)</span> and <span class="math notranslate nohighlight">\(\mathbb{P}_1\)</span> are <em>absolutely continuous</em> with respect to each other.)
For a definition of the likelihood function, see <a class="reference internal" href="bayes.html"><span class="doc std std-doc">Bayesian and Frequentist Estimation and Inference</span></a>.</p>
<p>A test based on a test function <span class="math notranslate nohighlight">\(\phi: \mathcal{X} \rightarrow [0, 1]\)</span> is implicitly
a randomized test if <span class="math notranslate nohighlight">\(\phi\)</span> can have a value strictly between 0 and 1.
Then, we also use an auxilliary randomness, <span class="math notranslate nohighlight">\(U \sim U[0,1]\)</span> and reject the null
if <span class="math notranslate nohighlight">\(U \ge \phi(X)\)</span>.
This is completely equivalent to the description above, but instead of thinking
in terms of a <em>set</em> <span class="math notranslate nohighlight">\(A \subset \mathcal{X} \times [0, 1]\)</span>, we think of a <em>function</em>
<span class="math notranslate nohighlight">\(\phi: \mathcal{X} \rightarrow [0, 1]\)</span>.
In both formulations, we use <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(U\)</span> to decide whether to reject <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
</section>
</section>
<section id="p-values">
<h2><span class="math notranslate nohighlight">\(P\)</span>-values<a class="headerlink" href="#p-values" title="Permalink to this headline">#</a></h2>
<p>Here are two approaches to defining <span class="math notranslate nohighlight">\(P\)</span>-values, in terms of families of hypothesis tests and in terms of a test statistic.</p>
<p>Family of tests:</p>
<ul class="simple">
<li><p>Suppose you have a set of nested (monotone) hypothesis tests:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\{A_\alpha : \alpha \in (0, 1] \}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{P}_0 \{ X \notin A_\alpha \} \le \alpha\)</span> (or more generally, <span class="math notranslate nohighlight">\(\mathbb{P} \{ X \notin A_\alpha \} \le \alpha, \; \forall \mathbb{P} \in \mathcal{P}_0\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(A_\alpha \subset A_\beta\)</span> if <span class="math notranslate nohighlight">\(\beta &lt; \alpha\)</span> (Can always re-define <span class="math notranslate nohighlight">\(A_\alpha \leftarrow \cup_{\beta \ge \alpha } A_\beta\)</span>)</p></li>
</ul>
</li>
<li><p>If we observe <span class="math notranslate nohighlight">\(X = x\)</span>, the <span class="math notranslate nohighlight">\(P\)</span>-value is <span class="math notranslate nohighlight">\(\sup \{ \alpha: x \in A_\alpha \}\)</span>.</p></li>
</ul>
<p>Test statistic definition of a <span class="math notranslate nohighlight">\(P\)</span>-value:</p>
<p>If <span class="math notranslate nohighlight">\(P = P(X)\)</span> is a random variable whose probability distribution is <em>dominated</em> by the uniform distribution on <span class="math notranslate nohighlight">\([0, 1]\)</span> when
the null hypothesis is true, then <span class="math notranslate nohighlight">\(P\)</span> is a <span class="math notranslate nohighlight">\(P\)</span>-value.</p>
<p>That is, <span class="math notranslate nohighlight">\(P\)</span> is a <span class="math notranslate nohighlight">\(P\)</span>-value if</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}  
 \mathbb{P}_0 \{ P(X) \le x \} \le x \;\; \forall x \in [0, 1].
\end{equation*}\]</div>
<p>You may hear someone say that a <span class="math notranslate nohighlight">\(P\)</span>-value is the chance that a test statistic is “as extreme or more extreme than
observed.”
That is not really a precise mathematical definition; moreover, not every <span class="math notranslate nohighlight">\(P\)</span>-value can be expressed naturally
in that form and not everything of that form is a <span class="math notranslate nohighlight">\(P\)</span>-value.</p>
<p>For randomized tests expressed in terms of acceptance regions, <span class="math notranslate nohighlight">\(P(X, U)\)</span> is a <span class="math notranslate nohighlight">\(P\)</span>-value if</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}  
 \mathbb{P}_0 \{ P(X,U) \le x \} \le x \;\; \forall x \in [0, 1].
\end{equation*}\]</div>
</section>
<section id="the-z-test">
<h2>The <span class="math notranslate nohighlight">\(Z\)</span>-test<a class="headerlink" href="#the-z-test" title="Permalink to this headline">#</a></h2>
<p>A <span class="math notranslate nohighlight">\(Z\)</span>-test tests the hypothesis that some function of the data has a standard Normal distribution, that is,
the hypothesis that for some given test statistic <span class="math notranslate nohighlight">\(f(x)\)</span>, <span class="math notranslate nohighlight">\(f(X) \sim N(0,1)\)</span>.</p>
<p>What kinds of things have a standard normal distribution?</p>
<ul class="simple">
<li><p>A random draw from a population that has a standard normal distribution.</p></li>
<li><p>The sample mean of <span class="math notranslate nohighlight">\(n\)</span> IID draws from a population that has a standard normal distribution, after multiplying the sample mean by <span class="math notranslate nohighlight">\(\sqrt{n}\)</span>.</p></li>
<li><p>The sample mean of <span class="math notranslate nohighlight">\(n\)</span> IID draws from a population that has a <span class="math notranslate nohighlight">\(N(\mu, \sigma^2)\)</span> distribution, after subtracting <span class="math notranslate nohighlight">\(\mu\)</span> and multiplying by <span class="math notranslate nohighlight">\(\sqrt{n}/\sigma\)</span>.</p></li>
</ul>
<p>The <span class="math notranslate nohighlight">\(Z\)</span>-test is often used as an <em>approximate</em> test rather than an <em>exact</em> test.
An <em>approximate</em> test is one that has approximately its nominal significance level.<br />
What kinds of things have distributions that are approximately standard normal?</p>
<ul class="simple">
<li><p>Things that have a Binomial<span class="math notranslate nohighlight">\((n, p)\)</span> distribution, after subtracting <span class="math notranslate nohighlight">\(np\)</span> and dividing by <span class="math notranslate nohighlight">\(\sqrt{np(1-p)}\)</span>, provided <span class="math notranslate nohighlight">\(np\)</span> and <span class="math notranslate nohighlight">\(n(1-p)\)</span> are not small. For instance, consider tossing a fair coin 100 times, independently. The number <span class="math notranslate nohighlight">\(X\)</span> of heads has a Binomial<span class="math notranslate nohighlight">\((100, 1/2)\)</span> distribution. The distribution of <span class="math notranslate nohighlight">\((X-50)/5\)</span> is approximately a standard normal. (<span class="math notranslate nohighlight">\(np(1-p) = 100\times 1/2 \times 1/2\)</span>, so <span class="math notranslate nohighlight">\(\sqrt{np(1-p)} = 5\)</span>.)</p></li>
<li><p>The sample mean of <span class="math notranslate nohighlight">\(n\)</span> IID draws with replacement from a finite population of numbers, after subtracting the population mean <span class="math notranslate nohighlight">\(\mu\)</span> and dividing by <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span>, where <span class="math notranslate nohighlight">\(\sigma\)</span> is the population standard deviation, provided <span class="math notranslate nohighlight">\(n\)</span> is sufficiently large and the population distribution is sufficiently “bell shaped.” If nothing is known about the population, it is in general impossible to know how accurate the normal approximation to the sample mean is.
(The Binomial distribution is a special case where the population values are known to be 0 and 1.)</p></li>
</ul>
<p>When the test statistic is only approximately normally distributed under the null hypothesis, the accuracy
of the approximation matters–but is rarely addressed.</p>
<section id="example-of-an-approximate-z-test-with-a-built-in-type-iii-error">
<h3>Example of an approximate <span class="math notranslate nohighlight">\(Z\)</span>-test with a built-in Type III error<a class="headerlink" href="#example-of-an-approximate-z-test-with-a-built-in-type-iii-error" title="Permalink to this headline">#</a></h3>
<p>There are two binary populations, <span class="math notranslate nohighlight">\(\{x_j\}_{j=1}^n\)</span> and <span class="math notranslate nohighlight">\(\{y_j\}_{j=1}^m\)</span>. (A population is <em>binary</em> if the only possible values in the population are 0 and 1.)
We are interested in whether the populations are “surprisingly different.”
The null hypothesis is that the two populations were formed by selecting <span class="math notranslate nohighlight">\(n\)</span> items at random from the overall group of <span class="math notranslate nohighlight">\(n+m\)</span> items to form the first population, with the remaining <span class="math notranslate nohighlight">\(m\)</span> items comprising the second population.</p>
<p>Let <span class="math notranslate nohighlight">\(\bar{x} := \frac{1}{n} \sum_j x_j\)</span> and <span class="math notranslate nohighlight">\(\bar{y} := \frac{1}{m} y_j\)</span>.
If <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> were independent random samples with replacement from the same binary “super-population” that had a fraction <span class="math notranslate nohighlight">\(p\)</span> of
1s and a fraction <span class="math notranslate nohighlight">\((1-p)\)</span> of zeros,
<span class="math notranslate nohighlight">\(n\bar{x}\)</span> would be a random variable with a binomial distribution with parameters <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(p\)</span>, and <span class="math notranslate nohighlight">\(m\bar{y}\)</span> would
be a random variable with
a binomial distribution with parameters <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(p\)</span>, and would be independent of <span class="math notranslate nohighlight">\(n\bar{x}\)</span>.</p>
<p>The expected value of <span class="math notranslate nohighlight">\(\bar{x}\)</span> would be <span class="math notranslate nohighlight">\(p\)</span> and its variance would be <span class="math notranslate nohighlight">\(p(1-p)/n\)</span>;
the expected value of <span class="math notranslate nohighlight">\(\bar{y}\)</span> would be <span class="math notranslate nohighlight">\(p\)</span> and its variance would be <span class="math notranslate nohighlight">\(p(1-p)/m\)</span>.
The expected value of <span class="math notranslate nohighlight">\(\bar{x} - \bar{y}\)</span> would be 0, and its variance would be <span class="math notranslate nohighlight">\(p(1-p)(1/n+1/m)\)</span>.
Moreover, if <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> were random samples with replacement from the same binary super-population,
<span class="math notranslate nohighlight">\(\hat{p} = (n\bar{x} + m\bar{y})/(n+m)\)</span> would be an unbiased estimate of <span class="math notranslate nohighlight">\(p\)</span>,
and for sufficiently large <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(n\)</span>, the distribution of</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
f(x,y) := \frac{\bar{x} - \bar{y}}{\sqrt{\hat{p}(1-\hat{p})(1/n+1/m)}}
\end{equation*}\]</div>
<p>would be approximately <span class="math notranslate nohighlight">\(N(0,1)\)</span>.
(The accuracy of the approximation would depend on <span class="math notranslate nohighlight">\(n\)</span>, <span class="math notranslate nohighlight">\(m\)</span>, and <span class="math notranslate nohighlight">\(p\)</span>.)</p>
<p>If we define the acceptance region <span class="math notranslate nohighlight">\(A := \{ x, y: |f(x, y)| \le z_{\alpha/2}\)</span>, where <span class="math notranslate nohighlight">\(z_\alpha\)</span> is the <span class="math notranslate nohighlight">\(1-\alpha\)</span>
percentage point of the standard normal distribution, we get a (two-sided) <span class="math notranslate nohighlight">\(Z\)</span> test at nominal significance
level <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p>But this is an approximate test of a different hypothesis: an approximate answer to a different question,
a Type III error.
The hypothesis test has little to do with the original hypothesis.
The true significance level of the test for the original null hypothesis that the two groups are a random partition
of the <span class="math notranslate nohighlight">\(n+m\)</span> items could be quite different from <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
</section>
<section id="numerical-example">
<h3>Numerical example<a class="headerlink" href="#numerical-example" title="Permalink to this headline">#</a></h3>
<p>There are two binary populations, <span class="math notranslate nohighlight">\(\{x_j\}_{j=1}^N\)</span> and <span class="math notranslate nohighlight">\(\{ y_j\}_{j=1}^M\)</span>.
Let <span class="math notranslate nohighlight">\(p_x\)</span> denote the mean of the first population and <span class="math notranslate nohighlight">\(p_y\)</span> the mean of the second.
We wish to know whether <span class="math notranslate nohighlight">\(p_x = p_y\)</span>.</p>
<p>A random sample with replacement of size <span class="math notranslate nohighlight">\(n = 100\)</span> will be drawn from the first list and a random sample with replacement of size <span class="math notranslate nohighlight">\(m = 300\)</span> will be drawn from the second list, independent of the other sample.
Let <span class="math notranslate nohighlight">\(X\)</span> denote the sum of the numbers in the sample from the first population and let <span class="math notranslate nohighlight">\(Y\)</span> denote the sum of the numbers in the sample from the second population.
Then <span class="math notranslate nohighlight">\(X \sim \mbox{Binom}(n, p_x)\)</span>, <span class="math notranslate nohighlight">\(Y \sim \mbox{Binom}(m, p_y)\)</span>, and <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are independent.</p>
<p>(An equivalent problem is that there are two coins, one with chance <span class="math notranslate nohighlight">\(p_x\)</span> of landing heads and one with chance <span class="math notranslate nohighlight">\(p_y\)</span> of landing heads. The first coin is tossed <span class="math notranslate nohighlight">\(n\)</span> times and the second coin is tossed <span class="math notranslate nohighlight">\(m\)</span> times.
All <span class="math notranslate nohighlight">\(m+n\)</span> tosses are independent. Let <span class="math notranslate nohighlight">\(X\)</span> be the number of times the first coin lands heads and let <span class="math notranslate nohighlight">\(Y\)</span>
denote the number of times the second coin lands heads.)</p>
<p>If <span class="math notranslate nohighlight">\(p_x = p_y = p\)</span>, <span class="math notranslate nohighlight">\(X+Y \sim \mbox{Binom}(n+m, p)\)</span> and <span class="math notranslate nohighlight">\(\hat{p} := (X+Y)/(n+m)\)</span> is an unbiased estimate of <span class="math notranslate nohighlight">\(p\)</span> with standard deviation <span class="math notranslate nohighlight">\(\sqrt{p(1-p)/(m+n)} \le 1/(2 \sqrt{m+n}) = 0.025\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(\bar{X} := X/n\)</span> and <span class="math notranslate nohighlight">\(\bar{Y} := Y/m\)</span>.
If <span class="math notranslate nohighlight">\(p_x = p_y = p\)</span> and <span class="math notranslate nohighlight">\(p\)</span> is not close to 0 or 1, then the distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is approximately Gaussian
with mean <span class="math notranslate nohighlight">\(p\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sqrt{p(1-p)/n}\)</span> and the distribution of <span class="math notranslate nohighlight">\(\bar{Y}\)</span> is approximately Gaussian
with mean <span class="math notranslate nohighlight">\(p\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sqrt{p(1-p)/m}\)</span>, and <span class="math notranslate nohighlight">\(\bar{X}\)</span> and <span class="math notranslate nohighlight">\(\bar{Y}\)</span> are independent.</p>
<p>It follows that the distribution of <span class="math notranslate nohighlight">\(\bar{X}-\bar{Y}\)</span> is approximately Gaussian with mean <span class="math notranslate nohighlight">\(p-p = 0\)</span> and standard deviation</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{eqnarray*}
\sigma := \sqrt{p(1-p)/n + p(1-p)/m} = \sqrt{p(1-p)}\sqrt{1/n + 1/m} \le 0.0577.
\end{eqnarray*}\]</div>
<p>Thus the distribution of</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\frac{\bar{X} - \bar{Y}}{\sqrt{p(1-p)}\sqrt{1/n + 1/m}}
\end{equation*}\]</div>
<p>is approximately the standard normal.
If we use the “plug-in” estimator of <span class="math notranslate nohighlight">\(p\)</span>, <span class="math notranslate nohighlight">\(\hat{p}\)</span>, the distribution is also approximately normal (but the accuracy of the approximation is, in general, worse).
Thus the distribution of</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
Z := \frac{\bar{X} - \bar{Y}}{\sqrt{\hat{p}(1-\hat{p})}\sqrt{1/n + 1/m}}
\end{equation*}\]</div>
<p>is approximately <span class="math notranslate nohighlight">\(N(0,1)\)</span> if <span class="math notranslate nohighlight">\(p_x = p_y\)</span>.</p>
<p>Note that if <span class="math notranslate nohighlight">\(p\)</span> is close to 0 or to 1, <span class="math notranslate nohighlight">\(\hat{p}\)</span> could end up equal to 0 or 1, in which case the denominator will
vanish (clearly underestimating the standard deviation of <span class="math notranslate nohighlight">\(\bar{X}-\bar{Y}\)</span>).</p>
<p>To perform a <span class="math notranslate nohighlight">\(Z\)</span> test, we pretend that the distribution of <span class="math notranslate nohighlight">\(Z\)</span> is exactly the standard normal.
If <span class="math notranslate nohighlight">\(p_x &gt; p_y\)</span>, we expect <span class="math notranslate nohighlight">\(\bar{X} &gt; \bar{Y}\)</span> and hence <span class="math notranslate nohighlight">\(Z &gt; 0\)</span>. If <span class="math notranslate nohighlight">\(p_x &lt; p_y\)</span>, we expect <span class="math notranslate nohighlight">\(\bar{X} &lt; \bar{Y}\)</span> and hence <span class="math notranslate nohighlight">\(Z &lt; 0\)</span>.
If we want the test to have power against both the possibility that <span class="math notranslate nohighlight">\(p_x &gt; p_y\)</span> and the possibility that <span class="math notranslate nohighlight">\(p_x &lt; p_y\)</span>, we would design the test to reject when <span class="math notranslate nohighlight">\(|Z|\)</span> is large.
To test at (approximate) level <span class="math notranslate nohighlight">\(\alpha\)</span>, we would reject with <span class="math notranslate nohighlight">\(|Z| &gt; z_{1-\alpha/2}\)</span>, the <span class="math notranslate nohighlight">\(1-\alpha/2\)</span> quantile of the standard normal distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># simulating the significance level of the Z-test</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span> <span class="c1"># the normal distribution</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">default_rng</span><span class="p">,</span> <span class="n">binomial</span>  <span class="c1"># this is the Mersenne Twister; there&#39;s much to consider in picking a PRNG.</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">default_rng</span><span class="p">(</span><span class="mi">1592592021</span><span class="p">)</span>   <span class="c1"># set the seed for reproducibility</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="c1"># significance level 5%</span>
<span class="n">z_c</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># normal quantile, critical value for the test</span>

<span class="n">p</span> <span class="o">=</span> <span class="p">[</span><span class="mf">.01</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mf">.3</span><span class="p">,</span> <span class="mf">.4</span><span class="p">,</span> <span class="mf">.5</span><span class="p">,</span> <span class="mf">.6</span><span class="p">,</span> <span class="mf">.7</span><span class="p">,</span> <span class="mf">.9</span><span class="p">,</span> <span class="mf">.95</span><span class="p">,</span> <span class="mf">.99</span><span class="p">]</span>  <span class="c1"># assortment of values for p</span>

<span class="n">reps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">6</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>  
<span class="n">m</span> <span class="o">=</span> <span class="mi">100</span> 

<span class="k">def</span> <span class="nf">absZ</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    absolute value of the Z statistic for the difference in sample sums from two binary populations</span>
<span class="sd">    </span>
<span class="sd">    Used in a Z test of the hypothesis that x and y are the sample sums of IID draws from binary</span>
<span class="sd">    populations with the same (unspecified) population fraction of 1s against the alternative</span>
<span class="sd">    hypothesis that the two population fractions differ.</span>
<span class="sd">    </span>
<span class="sd">    When the population percentages are close to 0 or 1, the sample percentages can be 0 or 1,</span>
<span class="sd">    in which case the estimated variance will be zero. In that situation, return -inf or inf, </span>
<span class="sd">    as appropriate.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">        sample size from first population</span>
<span class="sd">    m : int</span>
<span class="sd">        sample size from second population</span>
<span class="sd">    x : float</span>
<span class="sd">        sample sum of the draws from the first population</span>
<span class="sd">    y : float</span>
<span class="sd">        sample sum of the draws from the second population</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    z : float</span>
<span class="sd">        absolute value of the Z statistic</span>
<span class="sd">        </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">pHat</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="n">m</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="nb">abs</span><span class="p">((</span><span class="n">x</span><span class="o">/</span><span class="n">n</span> <span class="o">-</span> <span class="n">y</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">/</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">pHat</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">pHat</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)))</span>
           <span class="k">if</span> <span class="n">pHat</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">pHat</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
           <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">x</span><span class="o">/</span><span class="n">n</span> <span class="o">-</span> <span class="n">y</span><span class="o">/</span><span class="n">m</span><span class="p">))</span>

<span class="c1"># how precise should we expect the result to be?</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;max SD of alpha-hat: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">reps</span><span class="p">)))))</span>  <span class="c1"># max SD of a binomial is 1/2</span>

<span class="k">for</span> <span class="n">pj</span> <span class="ow">in</span> <span class="n">p</span><span class="p">:</span>
    <span class="n">reject</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">pj</span><span class="p">)</span> <span class="c1"># simulate X</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pj</span><span class="p">)</span> <span class="c1"># simulate Y. X and Y could be simulated together but the code would be less clear</span>
        <span class="n">reject</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> 
                  <span class="k">if</span> <span class="n">absZ</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">z_c</span>
                  <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;p=</span><span class="si">{}</span><span class="s1"> estimated alpha=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pj</span><span class="p">,</span> <span class="n">reject</span><span class="o">/</span><span class="n">reps</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>max SD of alpha-hat: 0.0005
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in double_scalars
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p=0.01 estimated alpha=0.033563
p=0.05 estimated alpha=0.039816
p=0.1 estimated alpha=0.049005
p=0.3 estimated alpha=0.050683
p=0.4 estimated alpha=0.052481
p=0.5 estimated alpha=0.057022
p=0.6 estimated alpha=0.052372
p=0.7 estimated alpha=0.050798
p=0.9 estimated alpha=0.049088
p=0.95 estimated alpha=0.039562
p=0.99 estimated alpha=0.03344
</pre></div>
</div>
</div>
</div>
<p>As you can see, the simulation estimate of the actual significance level differs from the nominal significance level, 5%, by more than simulation variability accounts for: the test is only approximate, and the accuracy of the approximation depends on the true value of <span class="math notranslate nohighlight">\(p\)</span>. The actual significance level is below 5% when the true <span class="math notranslate nohighlight">\(p\)</span> is near 0 or 1, and above 5% when the true <span class="math notranslate nohighlight">\(p\)</span> is near 1/2.</p>
<p>Now let’s look at the distribution of approximate <span class="math notranslate nohighlight">\(P\)</span>-values for (a one-sided version of) this test.
If <span class="math notranslate nohighlight">\(Z\)</span> really had a standard normal distribution, then for <span class="math notranslate nohighlight">\(z \ge 0\)</span>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\Pr \{|Z| \le z \} = 1 - 2\Phi(-z) =  2\Phi(z) - 1,
\end{equation*}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Phi\)</span> is the standard normal CDF.
Let <span class="math notranslate nohighlight">\(x := 2\Phi(z) - 1\)</span>.
Then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
x = \Pr \{ |Z| \le \Phi^{-1}((x+1)/2) \}
\end{equation*}\]</div>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
 = \Pr \{ \Phi(|Z|) \le (x+1)/2 \}
\end{equation*}\]</div>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
 = \Pr \{ 2\Phi(|Z|)-1 \le x \}.
\end{equation*}\]</div>
<p>Thus <span class="math notranslate nohighlight">\(2\Phi(|Z|)-1\)</span> would have a uniform distribution: it would be a <span class="math notranslate nohighlight">\(P\)</span>-value.</p>
<p>Let’s check whether that’s true.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">6</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># one of the worst offenders</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">reps</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># simulate X</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># simulate Y</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">absZ</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([136995.,  89683.,  86794.,  82063.,  78132., 139366.,  60161.,
        136581.,  95286.,  94939.]),
 array([0.        , 0.09999988, 0.19999976, 0.29999964, 0.39999952,
        0.49999939, 0.59999927, 0.69999915, 0.79999903, 0.89999891,
        0.99999879]),
 &lt;BarContainer object of 10 artists&gt;)
</pre></div>
</div>
<img alt="_images/tests_20_1.png" src="_images/tests_20_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">cumul</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="n">yi</span><span class="p">)</span> <span class="k">for</span> <span class="n">yi</span> <span class="ow">in</span> <span class="n">y</span><span class="p">])</span><span class="o">/</span><span class="n">reps</span>  <span class="c1"># simulated CDF</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">cumul</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Simulated distribution of nominal $P$ value for $P$=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/tests_21_0.png" src="_images/tests_21_0.png" />
</div>
</div>
<p>The (simulated) distribution is not dominated by the uniform.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">6</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.01</span>  <span class="c1"># one of the worst offenders</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">reps</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># simulate X</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># simulate Y</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">absZ</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in double_scalars
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([5.78410e+04, 1.00000e+00, 2.34340e+04, 1.13167e+05, 4.68700e+03,
        2.37444e+05, 1.13710e+05, 6.48320e+04, 1.24849e+05, 3.86530e+04]),
 array([0.        , 0.0999593 , 0.19991861, 0.29987791, 0.39983722,
        0.49979652, 0.59975583, 0.69971513, 0.79967444, 0.89963374,
        0.99959305]),
 &lt;BarContainer object of 10 artists&gt;)
</pre></div>
</div>
<img alt="_images/tests_23_2.png" src="_images/tests_23_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">num</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">cumul</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="n">yi</span><span class="p">)</span> <span class="k">for</span> <span class="n">yi</span> <span class="ow">in</span> <span class="n">y</span><span class="p">])</span><span class="o">/</span><span class="n">reps</span>  <span class="c1"># simulated CDF</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">cumul</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Simulated distribution of nominal $P$ value for $P$=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/tests_24_0.png" src="_images/tests_24_0.png" />
</div>
</div>
<p>Again, the (simulated) distribution is not dominated by the uniform. The <em>nominal</em> <span class="math notranslate nohighlight">\(P\)</span>-value based on treating the <span class="math notranslate nohighlight">\(Z\)</span>-statistic as if it had a standard normal distribution is not an <em>actual</em> <span class="math notranslate nohighlight">\(P\)</span>-value for this problem.</p>
</section>
<section id="an-exact-conditional-test-based-on-invariance-permutation-methods">
<h3>An exact conditional test based on invariance: permutation methods<a class="headerlink" href="#an-exact-conditional-test-based-on-invariance-permutation-methods" title="Permalink to this headline">#</a></h3>
<p>We now explore a different approach that yields an exact test rather than approximate test.</p>
<p>Let <span class="math notranslate nohighlight">\(N := n+m\)</span>.
Let <span class="math notranslate nohighlight">\(I_1, \ldots, I_n\)</span> be the values of the draws from the first population and <span class="math notranslate nohighlight">\(I_{n+1}, \ldots, I_N\)</span> be
the values of the draws from the second population.
Because the draws are all independent, <span class="math notranslate nohighlight">\(\{I_j\}\)</span> are independent random variables with a Bernoulli distribution.
If <span class="math notranslate nohighlight">\(p_x = p_y\)</span>, they are identically distributed also.</p>
<p>Define the random vector <span class="math notranslate nohighlight">\(I := (I_j)_{j=1}^N\)</span>.
Let <span class="math notranslate nohighlight">\(\pi\)</span> be a permutation of <span class="math notranslate nohighlight">\(1, 2, \ldots, N\)</span>.
(That is, <span class="math notranslate nohighlight">\(\pi = (\pi_1, \ldots, \pi_N)\)</span> is a vector of length <span class="math notranslate nohighlight">\(N\)</span> in which every number between <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(N\)</span> appears exactly once.)
Define the vector <span class="math notranslate nohighlight">\(I_\pi := (I_{\pi_j})_{j=1}^N\)</span>.
This vector has the same components as <span class="math notranslate nohighlight">\(I\)</span>, but in a different order (unless <span class="math notranslate nohighlight">\(\pi\)</span> is the identity permutation).
Because the draws are IID, the joint probability distribution of this permutation of the draws is
the same as the joint probability distribution of the original draws: the components of <span class="math notranslate nohighlight">\(I\)</span> are <em>exchangeable</em>
random variables if the null hypothesis is true.</p>
<p>Equivalently, let <span class="math notranslate nohighlight">\(z\)</span> be a vector of length <span class="math notranslate nohighlight">\(N\)</span>.
Then <span class="math notranslate nohighlight">\(\mathbb{P}_0 \{I = z \} = \mathbb{P}_0 \{I = z_\pi \}\)</span> for all <span class="math notranslate nohighlight">\(N!\)</span> permutations <span class="math notranslate nohighlight">\(\pi\)</span>.
Whatever vector of values <span class="math notranslate nohighlight">\(z\)</span> was actually observed, if the null hypothesis is true, all permutations of those values
were equally likely to have been observed instead.
In turn, that implies that all <span class="math notranslate nohighlight">\(\binom{N}{n}\)</span> multisubsets of size <span class="math notranslate nohighlight">\(n\)</span> of the <span class="math notranslate nohighlight">\(n+m\)</span> components of <span class="math notranslate nohighlight">\(z\)</span>
were equally likely to be the sample from the first population (with the other <span class="math notranslate nohighlight">\(m\)</span> values
comprising the sample from the second population).</p>
<p>Let <span class="math notranslate nohighlight">\(\{z\}\)</span> denote the <em>multiset</em> of elements of <span class="math notranslate nohighlight">\(x\)</span>.
(See, e.g., <a class="reference internal" href="math-foundations.html"><span class="doc std std-doc">Mathematical Foundations</span></a>
for the distinction between a set and a multiset.)
Consider the event that <span class="math notranslate nohighlight">\(\{I\} = \{z\}\)</span>, that is, that the multiset of observed data is equal to the multiset of
elements of <span class="math notranslate nohighlight">\(z\)</span>.
Then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
  \mathbb{P}_0(I = z_\pi | \{I\} = \{z\}) = \mathbb{P}_0(I = z | \{I\} = \{z\})
\end{equation*}\]</div>
<p>for all permutations <span class="math notranslate nohighlight">\(\pi\)</span> of <span class="math notranslate nohighlight">\(\{1, \ldots, n+m\}\)</span>.</p>
<p>It follows that the sample from the first population is equally likely to be any multisubset of <span class="math notranslate nohighlight">\(n\)</span> of the
<span class="math notranslate nohighlight">\(n+m\)</span> elements of the pooled sample, given the elements of the pooled sample.
That is, the conditional probability distribution of the sample from the first population is like that of a simple random sample of size <span class="math notranslate nohighlight">\(n\)</span> from the <span class="math notranslate nohighlight">\(N\)</span> elements of the pooled sample, given the elements of the pooled sample.</p>
<p>The pooled sample in this example consists of <span class="math notranslate nohighlight">\(G = \sum_{j=1}^N I_j\)</span> 1s and <span class="math notranslate nohighlight">\(N-G\)</span> 0s.
Given <span class="math notranslate nohighlight">\(G\)</span>, the conditional distribution of the number of 1s in the sample from the first population is hypergeometric with parameters <span class="math notranslate nohighlight">\(N=N\)</span> (population size), <span class="math notranslate nohighlight">\(G=G\)</span> (number of “good” items in the population), and <span class="math notranslate nohighlight">\(n=n\)</span> (sample size from the population).
Recall that <span class="math notranslate nohighlight">\(X\)</span> is the sum of the draws from the first population and <span class="math notranslate nohighlight">\(Y\)</span> is the sum of the draws from the second
population.
We have</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P}_0 \{ X = k | G=g \} = \left \{ \begin{array}{ll}
   \frac{\binom{g}{k}\binom{N-g}{n-k}}{\binom{N}{n}}, &amp; \max(0, g-m) \le k \le \min(n,g) \\
   0, &amp; \mbox{otherwise.}
   \end{array}
   \right .
\end{equation*}\]</div>
<p>Moreover, given <span class="math notranslate nohighlight">\(G\)</span>, <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are dependent, since <span class="math notranslate nohighlight">\(X+Y = G\)</span>.</p>
<p>We can base a (conditional) test of the hypothesis <span class="math notranslate nohighlight">\(p_0 = p_1\)</span> on the conditional
hypergeometric distribution of <span class="math notranslate nohighlight">\(X\)</span>.
Because the hypergeometric is discrete, for some values of <span class="math notranslate nohighlight">\(n\)</span>, <span class="math notranslate nohighlight">\(m\)</span>, <span class="math notranslate nohighlight">\(G\)</span>, and <span class="math notranslate nohighlight">\(\alpha\)</span> we will need a randomized
test <span class="math notranslate nohighlight">\(A=A_{\alpha;g}(\cdot, \cdot)\)</span> to attain exactly level <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p>What shall we use as the acceptance region?
To have power against the alternative that <span class="math notranslate nohighlight">\(p_x &gt; p_y\)</span> and the alternative <span class="math notranslate nohighlight">\(p_x &lt; p_y\)</span>, we should
reject if <span class="math notranslate nohighlight">\(X\)</span> is “too small” or if <span class="math notranslate nohighlight">\(X\)</span> is “too big.”
There are any number of ways we could trade off small and big.
For instance, we could make the acceptance region <span class="math notranslate nohighlight">\(A = A_{\alpha;g}(x,u)\)</span> nearly symmetric around
<span class="math notranslate nohighlight">\(\mathbb{E}(X|G) = nG/N\)</span>.
Or we could make the chance of rejecting when <span class="math notranslate nohighlight">\(X\)</span> is too small equal to the chance of rejecting when <span class="math notranslate nohighlight">\(X\)</span> is too big.</p>
<p>We will do something else: pick the acceptance region to include
as few values in <span class="math notranslate nohighlight">\(\{0, \ldots, n\}\)</span> as possible.
That means omitting from <span class="math notranslate nohighlight">\(A\)</span> the possible values of <span class="math notranslate nohighlight">\(X\)</span> that have the lowest (conditional) probabilities.
Because the hypergeometric distribution is unimodal, this yelds a test that rejects when <span class="math notranslate nohighlight">\(X\)</span> is “in the tails” of the hypergeometric distribution, as desired.
Let <span class="math notranslate nohighlight">\(\mathcal{K}\)</span> denote the largest subset of <span class="math notranslate nohighlight">\(\{0, \ldots, n\}\)</span> such that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P}_0 \{X \in \mathcal{K} | G=g \} &lt; \alpha,
\end{equation*}\]</div>
<p>Define</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathcal{J} := \arg \min_{j \notin \mathcal{K}} \mathbb{P}_0 \{ X = j | G=g \}
\end{equation*}\]</div>
<p>be the outcome or outcomes with smallest (conditional) probability not included in <span class="math notranslate nohighlight">\(\mathcal{K}\)</span>,
and let</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathcal{I} := \{0, \ldots, n\} \setminus (\mathcal{K} \cup \mathcal{J}).
\end{equation*}\]</div>
<p>Let</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\gamma := \frac{(1-\alpha) - \mathbb{P}_0 \{X \in \mathcal{I} | G=g \}}{\mathbb{P}_0 \{X \in \mathcal{J} |G=g\}}
\end{equation*}\]</div>
<p>be the fraction of the conditional probability of <span class="math notranslate nohighlight">\(\mathcal{J}\)</span> that needs to be added to the
conditional probability of <span class="math notranslate nohighlight">\(\mathcal{I}\)</span> to make
the conditional probability of their union equal <span class="math notranslate nohighlight">\(1-\alpha\)</span>.
Define the acceptance region</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
A_{\alpha; g} = \{ (x,u) \in \mathcal{I} \times [0,1] \} \cup \{ (x, u): x \in \mathcal{J} \mbox{ and } u \le \gamma \}.
\end{equation*}\]</div>
<p>Let <span class="math notranslate nohighlight">\(U\)</span> be a <span class="math notranslate nohighlight">\(U[0,1]\)</span> random variable independent of <span class="math notranslate nohighlight">\(X\)</span>.
Then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P}_0 \{ (X, U) \in A_{\alpha; g} | G=g \} = 1-\alpha.
\end{equation*}\]</div>
<p>That is, <span class="math notranslate nohighlight">\(A\)</span> is an acceptance region for a test of the null hypothesis with conditional significance level <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p>Conditioning on <span class="math notranslate nohighlight">\(G\)</span> eliminates the nuisance parameter <span class="math notranslate nohighlight">\(p\)</span>, the fraction of ones in the two populations
from which the sample was drawn: whatever <span class="math notranslate nohighlight">\(p\)</span> might be, and whatever the fraction of ones in the sample, every random sample of <span class="math notranslate nohighlight">\(n\)</span> of the <span class="math notranslate nohighlight">\(n+m\)</span> observations is equally likely to have been the sample from the first population, if the null hypothesis is true.
See <a class="reference internal" href="permute-intro.html"><span class="doc std std-doc">Introduction to Permutation Tests</span></a>.</p>
<p>This test, in a slightly different form, is called <em>Fisher’s Exact Test</em>.
It is useful for a wide range of problems, including clinical trials and A/B testing.</p>
</section>
<section id="illustration">
<h3>Illustration<a class="headerlink" href="#illustration" title="Permalink to this headline">#</a></h3>
<p>To visualize what’s going on, suppose <span class="math notranslate nohighlight">\(n=m=10\)</span> and <span class="math notranslate nohighlight">\(G=5\)</span>. Under the null, the conditional distribution of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(G=5\)</span> is hypergeometric with parameters <span class="math notranslate nohighlight">\(N=n+m=20\)</span>, <span class="math notranslate nohighlight">\(G=5\)</span>, and <span class="math notranslate nohighlight">\(n=10\)</span>.
The pmf of that distribution is plotted below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">hypergeom</span> <span class="c1"># the hypergeometric distribution</span>
<span class="n">n</span><span class="o">=</span><span class="mi">10</span>
<span class="n">m</span><span class="o">=</span><span class="mi">10</span>
<span class="n">N</span><span class="o">=</span><span class="n">n</span><span class="o">+</span><span class="n">m</span>
<span class="n">G</span><span class="o">=</span><span class="mi">5</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="n">pmf</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">G</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pmf</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;outcomes&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;hypergeometric pmf&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;pmf: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">pmf</span><span class="p">))))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/tests_28_0.png" src="_images/tests_28_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>pmf: [(0, 0.016253869969040196), (1, 0.13544891640866824), (2, 0.34829721362229055), (3, 0.34829721362229055), (4, 0.13544891640866824), (5, 0.016253869969040196), (6, 0.0), (7, 0.0), (8, 0.0), (9, 0.0), (10, 0.0)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># probability of rejecting when X \in {1, 5} to get overall level 0.05</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="p">(</span><span class="n">alpha</span><span class="o">-</span><span class="p">(</span><span class="n">pmf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">pmf</span><span class="p">[</span><span class="mi">5</span><span class="p">]))</span><span class="o">/</span><span class="p">(</span><span class="n">pmf</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">pmf</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0645714285714292
</pre></div>
</div>
</div>
</div>
<p>To construct the acceptance region for a level <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span> test, first notice that <span class="math notranslate nohighlight">\(\mathbb{P}_0\{X &gt; 5 | G=5\} = 0\)</span>, so the outcomes 6, 7, …, 10 should be outside <span class="math notranslate nohighlight">\(\mathcal{I}\)</span>.</p>
<p><span class="math notranslate nohighlight">\(\mathbb{P}_0\{X = 0 | G=5\} = \mathbb{P}_0\{X = 5 | G=5\} = 0.01625\)</span>, so if we exclude those outcomes from <span class="math notranslate nohighlight">\(\mathcal{I}\)</span>, the chance of rejecting the null is <span class="math notranslate nohighlight">\(2 \times 0.01625387 = 0.032508\)</span>.
For the test to have level <span class="math notranslate nohighlight">\(\alpha\)</span>, we need to reject more often: an additional <span class="math notranslate nohighlight">\(0.017492\)</span> of the time.
If we always rejected when <span class="math notranslate nohighlight">\(X=1\)</span> or <span class="math notranslate nohighlight">\(X=4\)</span>, we would reject too often, because each of those possibilities has probability <span class="math notranslate nohighlight">\(0.13545\)</span>.
If when <span class="math notranslate nohighlight">\(X \in \{1, 4\}\)</span> we reject with probability <span class="math notranslate nohighlight">\(\gamma = .01749/(2\times 0.13545) = 0.06457\)</span>, the overall chance of erroneously rejecting the null will be 5%, as desired.</p>
</section>
<section id="unconditional-tests-from-conditional-tests">
<h3>Unconditional tests from conditional tests<a class="headerlink" href="#unconditional-tests-from-conditional-tests" title="Permalink to this headline">#</a></h3>
<p>If you always test conditionally at level not greater than <span class="math notranslate nohighlight">\(\alpha\)</span>, that yields a test that has unconditional level not greater than <span class="math notranslate nohighlight">\(\alpha\)</span>, as we shall see.</p>
<p>Suppose we condition on the value of a discrete random variable, such as <span class="math notranslate nohighlight">\(G\)</span> in the previous example, then test at level not greater than <span class="math notranslate nohighlight">\(\alpha\)</span>, conditional on the value of <span class="math notranslate nohighlight">\(G\)</span>.
The unconditional significance level of the test is</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P}_0 \{\mbox{reject null}\} =
\sum_g \mathbb{P}_0 \{ \mbox{reject null} | G=g \} \mathbb{P}_0 \{G=g\}
\le \sum_g \alpha \mathbb{P}_0 \{G=g\} = \alpha \sum_g \mathbb{P}_0 \{G=g\} = \alpha,
\end{equation*}\]</div>
<p>where the sums are over all values <span class="math notranslate nohighlight">\(g\)</span> that <span class="math notranslate nohighlight">\(G\)</span> can take.</p>
<p>A similar proof establishes the result when <span class="math notranslate nohighlight">\(G\)</span> does not have a discrete distribution.</p>
</section>
<section id="numerical-comparison">
<h3>Numerical comparison<a class="headerlink" href="#numerical-comparison" title="Permalink to this headline">#</a></h3>
<p>We saw that the <span class="math notranslate nohighlight">\(Z\)</span>-test does not necessarily have its nominal level in this problem.
We now implement the permutation test (a randomized version of Fisher’s exact test) for comparison.</p>
</section>
<section id="algorithmic-considerations">
<h3>Algorithmic considerations<a class="headerlink" href="#algorithmic-considerations" title="Permalink to this headline">#</a></h3>
<section id="finding-mathcal-i-and-mathcal-j">
<h4>Finding <span class="math notranslate nohighlight">\(\mathcal{I}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{J}\)</span><a class="headerlink" href="#finding-mathcal-i-and-mathcal-j" title="Permalink to this headline">#</a></h4>
<p>In principle, we could sort the <span class="math notranslate nohighlight">\(n+1\)</span> values of the pmf to find the outcomes with the largest probabilities to include in <span class="math notranslate nohighlight">\(\mathcal{I}\)</span>, and the largest-probability outcomes not included in <span class="math notranslate nohighlight">\(\mathcal{I}\)</span> to be <span class="math notranslate nohighlight">\(\mathcal{J}\)</span> (if the test needs to be randomized to attain the desired significance level).</p>
<p>But the best sorting algorithms still take <span class="math notranslate nohighlight">\(n\log n\)</span> operations, and we don’t need a complete sort–we only need to divide the probabilities into two groups, the biggest and the rest.</p>
<p>However, because the hypergeomtric distribution is unimodal, the smallest probability will either be <span class="math notranslate nohighlight">\(\mathbb{P}_0 \{X = 0\}\)</span> or <span class="math notranslate nohighlight">\(\mathbb{P}_0 \{X = n\}\)</span> (or they will be equal).
After removing that outcome from consideration, the second-smallest probability will be either that of the largest remaining outcome or the smallest remaining outcome, etc. This means we can identify the outcomes to include in <span class="math notranslate nohighlight">\(\mathcal{I}\)</span> with a number of operations that is linear in <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># simulate the significance level of the permutation test</span>
<span class="k">def</span> <span class="nf">fisher_accept</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">G</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Acceptance region for randomized hypergeometric test</span>
<span class="sd">    </span>
<span class="sd">    Find the acceptance region for a randomized, exact level alpha test of </span>
<span class="sd">    the null hypothesis X~Hypergeometric(N, G, n). The acceptance region is</span>
<span class="sd">    the smallest possible. (And not, for instance, symmetric.)</span>

<span class="sd">    If a non-randomized, conservative test is desired, use the union of I and J </span>
<span class="sd">    as the acceptance region.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N:  integer</span>
<span class="sd">        population size</span>
<span class="sd">    G:  integer</span>
<span class="sd">        number of &quot;good&quot; items in the population</span>
<span class="sd">    n:  integer</span>
<span class="sd">        sample size</span>
<span class="sd">    alpha : float</span>
<span class="sd">        desired significance level    </span>
<span class="sd">  </span>
<span class="sd">    Returns</span>
<span class="sd">    --------</span>
<span class="sd">    I:  list</span>
<span class="sd">        observed values for which the test never rejects</span>
<span class="sd">    J:  list </span>
<span class="sd">        observed values for which the test sometimes rejects</span>
<span class="sd">    gamma : float</span>
<span class="sd">        probability the test does not reject when the observed value is in J</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">I</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                    <span class="c1"># start with all possible outcomes, then remove some</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">G</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>   <span class="c1"># hypergeometric pmf</span>
    <span class="n">bottom</span> <span class="o">=</span> <span class="mi">0</span>                     <span class="c1"># smallest outcome still in I</span>
    <span class="n">top</span> <span class="o">=</span> <span class="n">n</span>                        <span class="c1"># largest outcome still in I</span>
    <span class="n">J</span> <span class="o">=</span> <span class="p">[]</span>                         <span class="c1"># outcomes for which the test is randomized</span>
    <span class="n">p_J</span> <span class="o">=</span> <span class="mi">0</span>                        <span class="c1"># probability of the outcomes for which test is randomized</span>
    <span class="n">p_tail</span> <span class="o">=</span> <span class="mi">0</span>                     <span class="c1"># probability of outcomes not in I</span>
    <span class="k">while</span> <span class="n">p_tail</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>          <span class="c1"># still need to remove outcomes from the acceptance region</span>
        <span class="n">pb</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[</span><span class="n">bottom</span><span class="p">]</span>
        <span class="n">pt</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[</span><span class="n">top</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">pb</span> <span class="o">&lt;</span> <span class="n">pt</span><span class="p">:</span>                <span class="c1"># the smaller possibility has smaller probability</span>
            <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">bottom</span><span class="p">]</span>
            <span class="n">p_J</span> <span class="o">=</span> <span class="n">pb</span>
            <span class="n">bottom</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">pb</span> <span class="o">&gt;</span> <span class="n">pt</span><span class="p">:</span>              <span class="c1"># the larger possibility has smaller probability</span>
            <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">top</span><span class="p">]</span>
            <span class="n">p_J</span> <span class="o">=</span> <span class="n">pt</span>
            <span class="n">top</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>                      
            <span class="k">if</span> <span class="n">bottom</span> <span class="o">&lt;</span> <span class="n">top</span><span class="p">:</span>       <span class="c1"># the two possibilities have equal probability</span>
                <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">bottom</span><span class="p">,</span> <span class="n">top</span><span class="p">]</span>
                <span class="n">p_J</span> <span class="o">=</span> <span class="n">pb</span><span class="o">+</span><span class="n">pt</span>
                <span class="n">bottom</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">top</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>                  <span class="c1"># there is only one possibility left</span>
                <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">bottom</span><span class="p">]</span>
                <span class="n">p_J</span> <span class="o">=</span> <span class="n">pb</span>
                <span class="n">bottom</span> <span class="o">+=</span><span class="mi">1</span>
        <span class="n">p_tail</span> <span class="o">+=</span> <span class="n">p_J</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">J</span><span class="p">:</span>
            <span class="n">I</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_tail</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="n">p_J</span>     <span class="c1"># probability of accepting H_0 when X in J to get </span>
                                   <span class="c1"># exact level alpha</span>
    <span class="k">return</span> <span class="n">I</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="n">gamma</span>
        
    
<span class="k">def</span> <span class="nf">apply_test</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">U</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Apply a randomized test A to data x using auxiliary uniform randomness U</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    A:  triple</span>
<span class="sd">        first element is a list or set, the values of x for which the test never rejects</span>
<span class="sd">        second element is a list or set, the values of x for which the test sometimes rejects</span>
<span class="sd">        third element is a float in [0, 1], the probability of rejecting when x is in the second element</span>
<span class="sd">    x:  number-like</span>
<span class="sd">        observed data</span>
<span class="sd">    U:  float in [0, 1]</span>
<span class="sd">        observed value of an independent U[0,1] random variable</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    reject: Boolean</span>
<span class="sd">        True if the test rejects</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;probability out of range:</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">U</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;uniform variable out of range:</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
    <span class="k">return</span> <span class="ow">not</span><span class="p">(</span><span class="n">x</span> <span class="ow">in</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">or</span> <span class="p">(</span><span class="n">x</span> <span class="ow">in</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="n">U</span> <span class="o">&lt;=</span> <span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise: write unit tests of the two functions.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up the simulations</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="c1"># significance level 5%</span>
<span class="n">p</span> <span class="o">=</span> <span class="p">[</span><span class="mf">.01</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mf">.3</span><span class="p">,</span> <span class="mf">.4</span><span class="p">,</span> <span class="mf">.5</span><span class="p">,</span> <span class="mf">.6</span><span class="p">,</span> <span class="mf">.7</span><span class="p">,</span> <span class="mf">.9</span><span class="p">,</span> <span class="mf">.95</span><span class="p">,</span> <span class="mf">.99</span><span class="p">]</span>  <span class="c1"># assortment of values for p</span>

<span class="n">reps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">6</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">n</span><span class="o">+</span><span class="n">m</span>

<span class="c1"># how precise should we expect the result to be?</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;max SD of p-hat: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">reps</span><span class="p">)))))</span>  <span class="c1"># max SD of a binomial is 1/2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>max SD of p-hat: 0.0005
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1"># brute force: re-compute the test for each replication</span>
<span class="k">for</span> <span class="n">pj</span> <span class="ow">in</span> <span class="n">p</span><span class="p">:</span>
    <span class="n">reject</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">pj</span><span class="p">)</span> <span class="c1"># simulate X</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pj</span><span class="p">)</span> <span class="c1"># simulate Y</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">fisher_accept</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">X</span><span class="o">+</span><span class="n">Y</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">reject</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">apply_test</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">())</span>
                   <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;p=</span><span class="si">{}</span><span class="s1"> estimated alpha=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pj</span><span class="p">,</span> <span class="n">reject</span><span class="o">/</span><span class="n">reps</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p=0.01 estimated alpha=0.05001
p=0.05 estimated alpha=0.049823
p=0.1 estimated alpha=0.050227
p=0.3 estimated alpha=0.049927
p=0.4 estimated alpha=0.050298
p=0.5 estimated alpha=0.049955
p=0.6 estimated alpha=0.049959
p=0.7 estimated alpha=0.049856
p=0.9 estimated alpha=0.049854
p=0.95 estimated alpha=0.050085
p=0.99 estimated alpha=0.049817
CPU times: user 47min 31s, sys: 15.4 s, total: 47min 46s
Wall time: 47min 56s
</pre></div>
</div>
</div>
</div>
<p>This test has true significance level equal to its nominal significance level: it is an <em>exact</em> test rather than an <em>approximate</em> test.</p>
<p>Randomized tests have some drawbacks in practice.
For instance, it would be hard to explain to a consulting client or a judge that for a given set of data, the test you
propose to use sometimes
rejects the null hypothesis and sometimes does not, depending on a random factor (<span class="math notranslate nohighlight">\(U\)</span>) that has nothing to do
with the data or the experiment.</p>
<p>In such situations, it might make sense to use a <em>conservative</em> test rather than an exact randomized test.
A conservative test is one for which the chance of a Type I error is not greater than <span class="math notranslate nohighlight">\(\alpha\)</span>.
In the previous example, if the test rejects only when the test</p>
</section>
</section>
<section id="id1">
<h3>Algorithmic considerations<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>The previous simulation is <strong>slow</strong>, in part because it finds the conditional acceptance region
<code class="docutils literal notranslate"><span class="pre">reps</span></code> times for each <code class="docutils literal notranslate"><span class="pre">pj</span> <span class="pre">in</span> <span class="pre">p</span></code>.</p>
<p>But there are relatively few possible acceptance regions, one for each possible value of <span class="math notranslate nohighlight">\(G\)</span>, i.e., <span class="math notranslate nohighlight">\(n+m+1\)</span>.</p>
<p>What happens if we pre-compute the acceptance regions for all possible values of <span class="math notranslate nohighlight">\(G\)</span>, and look them up as needed?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1"># Smarter approach: pre-compute the tests. There are only n+m+1 possible tests, far fewer than reps</span>
<span class="c1"># Include the &quot;cost&quot; of precomputing the tests in the comparison.</span>

<span class="n">AA</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">AA</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fisher_accept</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">))</span>

<span class="k">for</span> <span class="n">pj</span> <span class="ow">in</span> <span class="n">p</span><span class="p">:</span>
    <span class="n">reject</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">pj</span><span class="p">)</span> <span class="c1"># simulate X</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pj</span><span class="p">)</span> <span class="c1"># simulate Y</span>
        <span class="n">reject</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> 
                   <span class="k">if</span> <span class="n">apply_test</span><span class="p">(</span><span class="n">AA</span><span class="p">[</span><span class="n">X</span><span class="o">+</span><span class="n">Y</span><span class="p">],</span> <span class="n">X</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">())</span> 
                   <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;p=</span><span class="si">{}</span><span class="s1"> estimated alpha=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pj</span><span class="p">,</span> <span class="n">reject</span><span class="o">/</span><span class="n">reps</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p=0.01 estimated alpha=0.050358
p=0.05 estimated alpha=0.050045
p=0.1 estimated alpha=0.049983
p=0.3 estimated alpha=0.050171
p=0.4 estimated alpha=0.05002
p=0.5 estimated alpha=0.049699
p=0.6 estimated alpha=0.049793
p=0.7 estimated alpha=0.049458
p=0.9 estimated alpha=0.049673
p=0.95 estimated alpha=0.050049
p=0.99 estimated alpha=0.050015
CPU times: user 1min 17s, sys: 295 ms, total: 1min 18s
Wall time: 1min 18s
</pre></div>
</div>
</div>
</div>
<p>This easy change speeds up the simulation by a factor of more than 40.</p>
<p>Alternatively, we can use the <code class="docutils literal notranslate"><span class="pre">functools</span></code> library to automatically cache the acceptance regions as they are computed.</p>
<p>Here’s the acceptance region function with the <code class="docutils literal notranslate"><span class="pre">&#64;lru_cache</span></code> decorator:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">lru_cache</span>

<span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># decorate the function to cache the results of calls to the function</span>
<span class="k">def</span> <span class="nf">fisher_accept</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Acceptance region for randomized hypergeometric test</span>
<span class="sd">    </span>
<span class="sd">    Find the acceptance region for a randomized, exact level alpha test of </span>
<span class="sd">    the null hypothesis X~Hypergeometric(N, G, n). The acceptance region is</span>
<span class="sd">    the smallest possible. (And not, for instance, symmetric.)</span>

<span class="sd">    If a non-randomized, conservative test is desired, use the union of I and J as </span>
<span class="sd">    the acceptance region.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N:  integer</span>
<span class="sd">        population size</span>
<span class="sd">    G:  integer</span>
<span class="sd">        number of &quot;good&quot; items in the population</span>
<span class="sd">    n:  integer</span>
<span class="sd">        sample size</span>
<span class="sd">    alpha : float</span>
<span class="sd">        desired significance level    </span>
<span class="sd">  </span>
<span class="sd">    Returns</span>
<span class="sd">    --------</span>
<span class="sd">    I:  list</span>
<span class="sd">        values for which the test never rejects</span>
<span class="sd">    J:  list </span>
<span class="sd">        values for which the test sometimes rejects</span>
<span class="sd">    gamma : float</span>
<span class="sd">        probability the test does not reject when the value is in J</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>          <span class="c1"># all possible values of X</span>
    <span class="n">I</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                    <span class="c1"># start with all possible outcomes, then remove some</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">G</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>   <span class="c1"># hypergeometric pmf</span>
    <span class="n">bottom</span> <span class="o">=</span> <span class="mi">0</span>                     <span class="c1"># smallest outcome still in I</span>
    <span class="n">top</span> <span class="o">=</span> <span class="n">n</span>                        <span class="c1"># largest outcome still in I</span>
    <span class="n">J</span> <span class="o">=</span> <span class="p">[]</span>                         <span class="c1"># outcome for which the test is randomized</span>
    <span class="n">p_J</span> <span class="o">=</span> <span class="mi">0</span>                        <span class="c1"># probability of the randomized outcome</span>
    <span class="n">p_tail</span> <span class="o">=</span> <span class="mi">0</span>                     <span class="c1"># probability of outcomes excluded from I</span>
    <span class="k">while</span> <span class="n">p_tail</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>          <span class="c1"># still need to remove outcomes from the acceptance region</span>
        <span class="n">pb</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[</span><span class="n">bottom</span><span class="p">]</span>
        <span class="n">pt</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[</span><span class="n">top</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">pb</span> <span class="o">&lt;</span> <span class="n">pt</span><span class="p">:</span>                <span class="c1"># the lower possibility has smaller probability</span>
            <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">bottom</span><span class="p">]</span>
            <span class="n">p_J</span> <span class="o">=</span> <span class="n">pb</span>
            <span class="n">bottom</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">pb</span> <span class="o">&gt;</span> <span class="n">pt</span><span class="p">:</span>              <span class="c1"># the upper possibility has smaller probability</span>
            <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">top</span><span class="p">]</span>
            <span class="n">p_J</span> <span class="o">=</span> <span class="n">pt</span>
            <span class="n">top</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>                      
            <span class="k">if</span> <span class="n">bottom</span> <span class="o">&lt;</span> <span class="n">top</span><span class="p">:</span>       <span class="c1"># the two possibilities have equal probability</span>
                <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">bottom</span><span class="p">,</span> <span class="n">top</span><span class="p">]</span>
                <span class="n">p_J</span> <span class="o">=</span> <span class="n">pb</span><span class="o">+</span><span class="n">pt</span>
                <span class="n">bottom</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">top</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>                  <span class="c1"># there is only one possibility left</span>
                <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">bottom</span><span class="p">]</span>
                <span class="n">p_J</span> <span class="o">=</span> <span class="n">pb</span>
                <span class="n">bottom</span> <span class="o">+=</span><span class="mi">1</span>
        <span class="n">p_tail</span> <span class="o">+=</span> <span class="n">p_J</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">J</span><span class="p">:</span>
            <span class="n">I</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_tail</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="n">p_J</span>     <span class="c1"># probability of accepting H_0 when X in J to get exact level alpha</span>
    <span class="k">return</span> <span class="n">I</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="n">gamma</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1"># re-run the original &quot;brute-force&quot; code but with function caching</span>
<span class="k">for</span> <span class="n">pj</span> <span class="ow">in</span> <span class="n">p</span><span class="p">:</span>
    <span class="n">reject</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">pj</span><span class="p">)</span> <span class="c1"># simulate X</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pj</span><span class="p">)</span> <span class="c1"># simulate Y</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">fisher_accept</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">X</span><span class="o">+</span><span class="n">Y</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">reject</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">apply_test</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">())</span>
                   <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;p=</span><span class="si">{}</span><span class="s1"> estimated alpha=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pj</span><span class="p">,</span> <span class="n">reject</span><span class="o">/</span><span class="n">reps</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p=0.01 estimated alpha=0.050092
p=0.05 estimated alpha=0.050045
p=0.1 estimated alpha=0.049978
p=0.3 estimated alpha=0.050282
p=0.4 estimated alpha=0.050424
p=0.5 estimated alpha=0.049985
p=0.6 estimated alpha=0.050117
p=0.7 estimated alpha=0.049918
p=0.9 estimated alpha=0.049929
p=0.95 estimated alpha=0.050044
p=0.99 estimated alpha=0.0501
CPU times: user 1min 21s, sys: 329 ms, total: 1min 21s
Wall time: 1min 22s
</pre></div>
</div>
</div>
</div>
<p>Again, this speeds up the simulation by a factor of more than 40, with even less coding effort.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exercise: How would you find a $P$-value for this test?</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Philip B. Stark<br/>
  
      &copy; Copyright 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>